\section{Introduction}
This section aims to equip the reader with both the motivation and mathematical 
tools to begin to formalise problems in mathematical finance. In section \ref{sec:1.2},
we will introduce the concepts of financial markets, order books, and dealers, and 
qualitatively describe how a dealer may wish to behave to optimise their revenue. We
will then use section \ref{sec:1.3} to briefly recap some basic measure and probability 
theory, before turning to stochastic processes in continuous time in section 
\ref{sec:1.4}. In sections \ref{sec:1.5} and \ref{sec:1.6}, we introduce stochastic 
calculus, looking at stochastic integration, It\^{o}'s lemma, and finally stochastic 
differential equations and the existence and uniqueness of their solutions.

\section{Financial Markets}\label{sec:1.2}
A market is simply some social structure that attempts to match those who want to 
sell a good or service to those who want to buy it. Modern financial markets, 
thanks to recent innovations such as the internet, satellite communication, and 
fibre-optic cables, are perhaps the most interconnected and widespread markets in 
human history. 

Most people may have heard of the New York Stock Exchange, London Stock Exchange, 
or NASDAQ, but these are only one type of exchange for one type of financial asset, 
namely equity (part ownership of a corporate entity, individually called ``stocks'' 
or ``shares'').There are also markets for commodities (oil, gas, industrial metals, 
precious metals, live cattle and more), bonds (pieces of government or corporate 
debt, where the holder receives fixed interest payments), currencies (including 
cryptocurrencies), and derivatives which are legal contracts whose value is some 
function of the price of a specified underlying asset. In total, on an average day, 
tens of trillions of US dollars worth of assets change hands.

All markets, whatever the good or service being exchanged, have something in common: 
Every seller needs a buyer, and every buyer needs a seller. But this raises some 
natural questions: What happens if no-one wants to sell (or buy)? What happens if 
the only prices at which people are willing to sell is far out of reach of those 
who want to buy? Enter the \textit{dealer}: An entity who provides \textit{liquidity} 
(ease of exchange) to market participants. A dealer does this by simultaneously 
offering to both buy and sell the particular asset, offering to buy at a slightly 
lower price than they offer to sell. This known as ``making a market'', and dealers 
in modern parlance may also be called ``market-makers''.

\subsection*{Dealers}
Dealers provide a crucial service in financial markets: By providing these quotes, 
they narrow the \textit{spread} - the difference between the prices at which one can 
buy or sell an asset in the market. Hence, entities who may need to trade even in 
adverse market scenarios (such as companies needing to buy foreign currency to pay 
workers abroad, or oil producers seeking to hedge their production) know that they 
can reliably find a buyer or seller, regardless of the uncertainty of other market 
participants such as \textit{speculators} - those believe that a certain asset is 
under or overvalued, and trade it with the sole motive of making money buy selling 
it for more than they bought it or vice-versa.

Of course, there is no free lunch. Dealers do not provide this service to the market 
out of the goodness of their own hearts - they too have a profit motive. While the 
presence of dealers in the market narrows the spread, it does not eliminate it. 
The dealers aim is to be constantly selling the asset for a slightly higher price 
than it is buying it, and taking the spread as profit. In modern electronic markets 
with very high trading volumes, even in heavily traded assets with very narrow 
spreads, a spread of only 0.01\$ multiplied across millions or billions of trades 
can be very lucrative for the dealers who are fast enough.

\subsection*{The Limit Orderbook}
So far we have discussed markets as an abstract concept, but in order to build a 
mathematical model of the dealer, we need to specify the framework under which the 
market operates. Most modern electronic exchanges, including those mentioned above, 
operate some version of a \textit{limit orderbook} where participants can place two 
types of orders: a \textit{limit order} or a \textit{market order} depending on their 
needs. Limit orders specify a side (bid or ask, buying or selling), a quantity (how 
many units of the asset to buy/sell), and a price at which the order should be 
executed. These enter a queue of limit orders at the particular price level. Market 
orders specify a side and a quantity, but not a price: The exchange operates a 
\textit{matching engine} which takes incoming market orders and attempts to match 
them to the existing limit orders, and if two orders match, they are executed and a 
trade occurs. 

For an example, consider the orderbook illustrated by figure \ref{fig:orderbook}, and
suppose that individual limit orders may only be placed for 1-share lots. If a market 
order is placed to buy 10 lots, then the trade will occur at \$1.01, the dealer/s will 
sell and the placer of the market order will buy, and both the market order and the 10
lowest limit ask orders will be removed from the market. So immediately after this 
trade, there will be 20 shares left available to be sold at the \$1.01 price level. 
However, suppose that a market order is placed to buy 30 units. In this case, the 
orders will still be matched, the buyer will buy 30 units for \$1.01 apiece but all of 
the limit orders at \$1.01 will be taken off the exchange, and the market mid-point 
price has now moved up from \$1.00 to \$1.005. If a market order is placed to buy 100
shares, since there are only 80 shares available to be sold, only these 80 will be 
bought for an average price of $\frac{30\times1.01\$+50\times1.02\$}{80}=1.01625\$.$
On the other hand, if a market order is placed and there are no limit orders to match 
it against, the market order would not be executed at all and be voided.

Finally, suppose we place a limit 
order into this market to buy 10 shares for \$0.90. Thus, for our order to ever be 
executed, a market order or sequence of market orders would have to come in and move
the market mid-price by $\approx10\%$ in order for our order to be touched. Hence in a 
given (small) interval of time, it is intuitively very unlikely that our order will
be executed, especially when you consider that a move of $10\%$ is roughly how 
much you might expect a stock to move over a year, let alone over a fraction of a 
trading day. This is one of the fundamental ideas that we will employ to model our 
dealing agent: The probability that a limit order will execute is a decreasing 
function of its distance from the mid-price.

\begin{figure}
\centering
    \begin{tabular}{ |c|c|c| } 
        \hline
        Side & Price /\$ & Volume \\ 
        \hline
        A & 1.02 & 50 \\
        A & 1.01 & 30 \\
        N/A & 1.00 & 0 \\
        B & 0.99 & 25 \\ 
        B & 0.98 & 45 \\
        \hline
    \end{tabular}
    \caption{An example orderbook}
    \label{fig:orderbook}
\end{figure}

We have also seen the key difference between market and limit orders in action: Limit 
orders guarantee price, but do not guarantee that all or any of the order will be 
filled. Market orders guarantee that as much of the order as possible will be filled, 
but they do not guarantee the price at which the trade will occur.

We can also observe that the market provides us with a way to estimate the true value 
of the asset. Classical economic theory dictates that in aggregate, market participants 
react quickly and rationally to new information about a particular asset, meaning that 
market prices reflect the consensus opinion of market participants about the value of 
traded assets. The spread exists because people would only want to sell for slightly 
more than something is worth, and buy it for slightly less. Hence, if you really want 
to buy an asset you have to pay a premium to ``\textit{cross the spread}'' to acquire 
it. From this we can determine that the true price of the asset at a point in time 
lies somewhere in between the maximum bid price and the minimum ask price for the asset 
at that time. The most common estimator in the literature and in practice is simply 
the average of these two values - the mid-market price, but other estimators do exist 
such as the volume-weighted average price (VWAP) which takes into account the volume 
of the bids vs asks. For the rest of this report we will use the mid-price as our 
estimator for the ``true'' value of an asset.

The aim for the rest of this report is to build up a model of how a dealer should 
behave to maximise their returns in the presence of uncertainty: namely, uncertainty 
about the path that the true value of the stock might take. In order to do this, we 
will need to make use of some basic results from measure/probability theory and 
stochastic processes, which we will summarise below. We will also briefly introduce 
some tools from stochastic calculus. Familiarity with standard results from a 
first-year undergraduate level course in real analysis, probability, and statistics 
is assumed. Most of the results in section \ref{sec:1.3} come from the third year
Measure Theory and Integration or Martingale Theory with Applications courses. Section
\ref{sec:1.4} recaps content from Probability 2 and Martingale Theory, and also brings
in some new material which is cited. Sections \ref{sec:1.5} and \ref{sec:1.6} contain 
mostly new material, although some was covered towards the end of the Financial 
Mathematics unit. We skip the vast majority of proofs in the interest of brevity 
and readability, they are not the point of this project. 

\section{Measure Theory and Probability}\label{sec:1.3}

We begin by formalising the notion of what ``events'' in a probability space are.
In elementary treatments of probability theory, the set of events is given no particular 
structure, but, especially with uncountable sample spaces, this can lead to inconsistencies.

\begin{definition}[$\sigma$-algebra]
    A family $\mathcal{F}\subseteq\mathcal{P}(\Omega)$ of sets is called a $\sigma$-algebra if 
    \begin{itemize}
        \item $\Omega\in\mathcal{F},$
        \item for every countable collection of sets $A_1,A_2,...\in\mathcal{F},\;\bigcup_{n}A_n\in\mathcal{F},$
        \item for every $A\in\mathcal{F}, A^{\mathrm c}\in\mathcal{F}.$
    \end{itemize}
\end{definition}

\begin{remark}
    The pair $(\Omega,\mathcal{F})$ is called a \emph{measurable space}. Any set $A\in\mathcal{F}$
    is called $\mathcal{F}$-\emph{measurable} or simply \emph{measurable}.
\end{remark}

A measure, which we define next, is simply a function that assigns a magnitude 
to a measurable set. In $\mathbb{R}^n$, the canonical measure is the Lebesgue 
measure, which in one dimension is also called length, in two area, in three volume,
and so on. In the context of probability theory, the ``magnitude'' of an event is 
simply the likelihood that it will occur.

\begin{definition}
    A \emph{measure} $\mu$ on a $\sigma$-algebra $\mathcal{F}$ is a set function
    $\mu:\mathcal{F}\rightarrow[0,\infty]$ such that $\forall$ mutually disjoint
    sets $A_1,A_2,...\in\mathcal{A}$ with $\bigcup_nA_n\in\mathcal{A},$
    \begin{equation}
        \mu\left(\bigcup_{n=1}^{\infty}A_n\right)=\sum_{n=1}^{\infty}\mu(A_n)
    \end{equation}
\end{definition}

\begin{remark}
    The triplet $(\Omega,\mathcal{F},\mu)$ is called a measure space. If $\mu(\Omega)
    =1$ then we call $\mu$ a \emph{probability measure}, and often use $\mathbb{P}$ 
    instead. In this case the triplet $(\Omega,\mathcal{F},\mathbb{P})$ is called a 
    \emph{probability space}.
\end{remark}

Next we see that we can generate $\sigma$-algebras from sets of sets, and use 
this to construct the Borel $\sigma$-algebra on $\mathbb{R}$. This is the canonical
$\sigma$-algebra for use over $\mathbb{R}$ as it contains all Lebesgue-measurable 
sets, and hence almost all interesting sets, except those that are interesting 
precisely because they are not Lebesgue-measurable, such as the Vitali set.

\begin{lemma}
    Let $\mathcal{A}\subseteq\mathcal{P}(\Omega)$ Then $\exists$ a smallest $\sigma$-algebra 
    $\sigma(\mathcal{A})$ that contains all sets from $\mathcal{A}.$
\end{lemma}
\begin{proof}
    The intersection of $\sigma$-algebras is a $\sigma$-algebra, so to find the 
    smallest containing some collection of sets, take the intersection of all $\sigma$-
    algebras containing those sets.
\end{proof}

\begin{remark}
    The above $\sigma(\mathcal{A})$ is usually called the $\sigma$-algebra
    \emph{generated} by $\mathcal{A}$.
\end{remark}

\begin{definition}[The Borel $\sigma$-algebra]
    Consider the collection 
    \begin{equation*}
        \mathcal{A}=\{(a,b):a,b\in\mathbb{R}\cup\{-\infty,\infty\},a<b\}
    \end{equation*}
    Then define $\mathcal{B}(\mathbb{R}):=\sigma(\mathcal{A})$ the \emph{Borel 
    $\sigma$-algebra}. This is the smallest $\sigma$-algebra containing all open
    sets in $\mathbb{R}$. A set $B\in\mathcal{B}$ is a \emph{Borel set}.
\end{definition}

Next we turn to functions whose domain is a measurable space. We also look at simple 
functions, define the integral of a simple function, approximate non-negative measurable
functions by simple functions and arrive at the notion of the Lebesgue integral, a slightly
stronger integral than the Riemann or Regulated integral studied in a first year course.

\begin{definition}[Measurable functions]
    Let $(\Omega,\mathcal{F})$ be a measurable space. A function $f:\Omega\rightarrow\mathbb{R}$
    is \emph{measurable} if for any $B\in\mathcal{B}$,
    \begin{equation*}
        f^{-1}(B)\in\mathcal{F}.
    \end{equation*}
\end{definition}

\begin{definition}[Simple functions]
    A \emph{simple function} is a finite linear combination of 
    characteristic (or indicator) functions of measurable sets:
    \begin{equation}
        \phi=\sum_{i=1}^nc_i\chi_{A_i}
    \end{equation}
    where $c_i\in\mathbb{R}$ and $A_i\in\mathbb{X}$.
    It is in standard representation if $X=\cup_{i=1}^nA_i$,
    the sets $A_i$ are pairwise disjoint, and the numbers $c_i$
    are distinct.
\end{definition}

\begin{definition}[Integral of a simple function]
    Consider a non-negative simple function written in standard form as given above.
    Then the \emph{integral} of $\phi$ \emph{with respect to $\mu$} is
    \begin{equation}
        \int\phi\mathrm d\mu:=\sum_{i=1}^nc_i\mu(A_i)
    \end{equation}
    which takes values in $\bar{\mathbb{R}}$.
\end{definition}

\begin{lemma}[Approximation by simple functions]
    Let $f\in M(X,\mathbb{X})$, $f\geq0.$ Then there exists a sequence
    $(\phi_n)$ in $M(X,\mathbb{X})$ such that
    \begin{itemize}
        \item $0\leq\phi_n(x)\leq\phi_{n+1}(x)\;\forall\;x\in X,n\in\mathbb{N}$,
        \item $\lim_{n\rightarrow\infty}\phi_n(x)=f(x)$,
        \item Each $\phi_n$ is a simple function.
    \end{itemize}
\end{lemma}

\begin{definition}[Integral of a non-negative measurable function]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$ 
    \emph{with respect to $\mu$} is 
    \begin{equation*}
        \int f\mathrm d\mu := \sup\left\{\int\phi\mathrm d\mu : 0\leq\phi\leq f, \phi\textrm{ is a simple measurable function}\right\}\in\bar{\mathbb{R}}.
    \end{equation*}
\end{definition}

\begin{definition}[Integral of a non-negative measurable function over a set]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$
    \emph{with respect to $\mu$ over set $A\in \mathbb{X}$} is
    \begin{equation}
        \int_A f\mathrm d\mu:=\int f\chi_A\mathrm d\mu
    \end{equation}
\end{definition}

\begin{definition}[Integrable functions]
    Let $(X,\mathbb{X},\mu)$ be a measure space. $f:X\rightarrow\mathbb{R}$
    is \emph{integrable} iff 
    \begin{equation}
        \int f^+\mathrm d\mu<+\infty \textrm{ and }\int f^-\mathrm d\mu<+\infty
    \end{equation}
    where $f^+:=\max\{f,0\}$ and $f^-:=-\min\{f,0\}$.
    We then define
    \begin{equation}
        \int f\mathrm d\mu:=\int f^+\mathrm d\mu -\int f^-\mathrm d\mu
    \end{equation}
    and for $A\in\mathbb{X}$
    \begin{equation}
        \int_A f\mathrm d\mu:=\int_A f^+\mathrm d\mu -\int_A f^-\mathrm d\mu
    \end{equation}
\end{definition}

\begin{remark}
    All of the standard properties of integrals that one would expect
    to hold such as linearity are also true for the Lebesgue integral 
    defined above. The Lebesgue integral also coincides with the Riemann
    and Regulated integrals for all Riemann-integrable and regulated functions respectively.
\end{remark}

Now we have seen a brief introduction to measure theory and integration, we turn to 
probability theory. As it turns out, probability theory is almost entirely a special
case of measure theory, where, as mentioned above, the measure of the full space is one.

\begin{definition}[Random variables]
    Recall from above that a probability space \\$(\Omega,\mathcal{F},\mathbb{P})$
    is simply a measure space $(X,\mathbb{X},\mu)$ where $\mu(X)=1.$ In this case,
    a measurable function $X:\Omega\rightarrow\mathbb{R}$ can be called
    a random variable. 
\end{definition}

\begin{definition}[Expectation]
    The notion of the \emph{expectation} of a \textbf{random variable} is exactly equivalent
    to the notion of the \emph{integral} of a \textbf{measurable function}.
    To be precise,
    \begin{equation}
        \mathbb{E}[X]:=\int X\mathrm d\mathbb{P}
    \end{equation}
\end{definition}

\begin{definition}[$\sigma-$algebra generated by a random variable]
    The $\sigma$-algebra generated by a random variable $Y:\Omega\rightarrow\mathbb{R}$
    is $\sigma(Y):=\sigma(Y^{-1}(\mathcal{B}(\mathbb{R})))$.
\end{definition}

\begin{definition}[Conditional Expectation]
    Suppose $\mathcal{H}\subseteq\mathcal{F}$ is a sub-$\sigma$-algebra
    of $\mathcal{F}.$ Then a \emph{conditional expectation} of random variable
    $X$ given $\mathcal{H}$, is any $\mathcal{H}$-measurable function 
    $V:\Omega\rightarrow\mathbb{R}$ with $\mathbb{E}[V]<\infty$ which satisfies
    \begin{equation}
        \int_H V\mathrm d\mathbb{P}=\int_H X\mathrm d\mathbb{P}
    \end{equation}
    for any $H\in\mathcal{H}$. We then define the notational convenience
    \begin{equation}
        \mathbb{E}[X|\mathcal{H}]:=V.
    \end{equation}
    The conditional expectation with respect to a random variable is defined according
    to
    \begin{equation}
        \mathbb{E}[X|Y]:=\mathbb{E}[X|\sigma(Y)]
    \end{equation}
    where $\sigma(Y)$ is the $\sigma$-algebra generated by $Y$.
\end{definition}

\begin{theorem}[Tower rule / Law of iterated conditional expectation]
    Let $X$ be a random variable on probability space $(\Omega,\mathcal{F},\mathbb{P})$
    with $\mathbb{E}[|X|]<\infty$. Let $\mathcal{G}\subset\mathcal{H}$ be sub $\sigma$-
    algebras, $\mathcal{G}$ the courser and $\mathcal{H}$ the finer. Then:
    \begin{equation}
        \mathbb{E}[\mathbb{E}[X|\mathcal{G}]|\mathcal{H}]=\mathbb{E}[\mathbb{E}[X|\mathcal{H}]|\mathcal{G}]=\mathbb{E}[X|\mathcal{G}]
    \end{equation}
\end{theorem}

All of these results are slight generalisations of results encountered in school or 
a first year course. We now turn to a useful theorem from measure theory concering 
the swapping of integrals (or integral and expectation, since expectation is 
equivalent to integration in the probability space).

\begin{theorem}[Fubini-Tonelli]
    Let $(\Omega,\mathcal{F},\mathbb{P})$ and $(\mathbb{R},\mathcal{B},\lambda)$
    be two $\sigma$-finite measure spaces (this is a technical condition beyond the 
    scope of this introduction, all measure spaces encountered from here on out will
    be $\sigma$-finite). Let $f:\Omega\times\mathbb{R}\rightarrow\mathbb{R}$ be a 
    measurable function w.r.t. both measure spaces. Then
    \begin{equation}\label{eq:1.13}
        \int\int f(x,y)\mathrm d\mathbb{P}\mathrm d\lambda=\int\mathbb{E}[f(x,y)]\mathrm d\lambda=\mathbb{E}\left[\int f(x,y)\mathrm d\lambda\right]=\int \int f(x,y)\mathrm d\lambda\mathrm d\mathbb{P}
    \end{equation}
\end{theorem}

\begin{definition}[Moment Generating Functions]
    The \emph{Moment Generating Function} (MGF) of a random variable $X$ is defined as follows
    \begin{equation}
        M_X(t):=\mathbb{E}[e^{tX}]
    \end{equation}
\end{definition}

\begin{remark}
    The MGF of the normal distribution is a commonly used tool when dealing with
    Brownian Motion and functions of Brownian Motion as we will do throughout this
    report. Suppose $X\sim\mathcal{N}(\mu,\sigma^2)$. Then
    \begin{equation}
        M_X(t)=\mathbb{E}[e^{tX}]=e^{t\mu+\frac{t^2\sigma^2}{2}}
    \end{equation}
\end{remark}

\section{Stochastic Processes}\label{sec:1.4}

Next we move on to look at Stochasic Processes, which are nothing more than sequences
of random variables, typically viewed as moving through time. Going forward, we will 
need a few properties regarding measurability and some common examples of widely used 
stochastic processes for modelling real-world phenomena. Firstly, we need to introduce 
some extra structure to our probability space, representing the information about the 
process that we recieve over time.

\begin{definition}[Filtrations \& Adaptedness]
    A \emph{filtered space} is $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n=0}^\infty,\mathbb{P})$
    where $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space and 
    $\mathcal{F}_0\subseteq\mathcal{F}_1\subseteq\dots\subseteq\mathcal{F}$
    are $\sigma$-algebras, jointly called a \emph{filtration.} We also define
    $\mathcal{F}_\infty:=\sigma(\cup_n\mathcal{F}_n)\subseteq\mathcal{F}.$ 
    
    We say a stochastic process or sequence of random variables $X_n$ is adapted to
    the filtration $(\mathcal{F}_n)_{n\geq0}$ if for every $n$, $X_n$ is $\mathcal{F}_n$
    -measurable. 
\end{definition}

\begin{definition}[Martingales]
    A process $(M_n)_{n\geq0}$ in a filtered probability space is a
    \emph{martingale with respect to a filtration $(\mathcal{F}_n)_{n\geq0}$}
    if
    \begin{itemize}
        \item $M_n$ is adapted to $\mathcal{F}_n$,
        \item $\mathbb{E}[M_n]<\infty\;\forall\;n\geq0$,
        \item $\mathbb{E}[M_{n+1}|\mathcal{F}_n]=M_n\textrm{ a.s. }\forall\;n\geq0.$
    \end{itemize}
\end{definition}

\begin{definition}[(Inhomogeneous) Poisson Process]
    Let $\lambda:\mathbb{R}\rightarrow[0,\infty)$ be a measurable and
    integrable function such that for every bounded set $B$ the integral of 
    $\lambda$ is finite:
    \begin{equation}
        \Lambda(B)=\int_B\lambda(x)\mathrm dx<\infty
    \end{equation}
    Then for every collection of disjoint bounded Borel-measurable sets
    $B_1,\dots,B_k$, an inhomogeneous \emph{Poisson Point Process} with
    \emph{intensity function} $\lambda$ has distribution
    \begin{equation}
        \mathbb{P}\{N(B_i)=n_i,i=1,\dots,k\}=\prod_{i=1}^k\frac{(\Lambda(B_i))^{n_i}}{n_i!}e^{-\Lambda(B_i)}.
    \end{equation}
    Moreover,
    \begin{equation}
        \mathbb{E}[N(B)]=\Lambda(B).
    \end{equation}
\end{definition}

\begin{definition}[Brownian Motion]
    Let $\mathcal{F}_t$ be a filtration. A stochastic process $W=(W_t)_{t\geq0}$
    is a standard one-dimensional \emph{Brownian Motion} or \emph{Wiener Process}
    if it satisfies the following:
    \begin{itemize}
        \item $W_0=0$ a.s.,
        \item Independent increments: $W_{t+s}-W_t$ is independent of $\mathcal{F}_t\;\forall\;t,s\geq0$,
        \item $W$ has stationary Gaussian increments: $W_{t+s}-W_t\sim\mathcal{N}(0,s)$,
        \item $W$ has continuous sample paths: $W_t(\omega)$ is a continuous function of $t\;\forall\;\omega\in\Omega$.
    \end{itemize}
\end{definition}

\begin{definition}[Predictable Processes]
    A stochastic process $X_t$ is \emph{predictable} (in the discrete sense) 
    if $X_{t+1}$ is $\mathcal{F}_{t}$ measurable for all $t$. 
    
    If $X_t$ is a continous stochastic process, then it is predictable if it is 
    measurable with respect to the $\sigma$-algebra generated by all left-continuous
    adapted processes. 
    
    This includes all left-continuous stochastic processes, 
    since we can find $X_t$ by finding $\lim_{s\rightarrow t^-}X_s$ without needing 
    to observe $X$ at time $t$.
\end{definition}

\begin{definition}[Stopping Times]
    A random variable $\tau:\Omega\rightarrow[0,\infty]$ is a stopping time (with
    respect to the filtration $\mathcal{F}$) if $\forall\;t\in[0,T]$
    \begin{equation}
        \{\tau\leq t\}:=\{\omega\in\Omega:\tau(\omega)\leq t\}\in\mathcal{F}_t.
    \end{equation}
\end{definition}

This concept will be very useful later on when we look at the dynamic programming 
principle. In particular, any random time equal to a positive constant $t$ is a 
stopping time. We conclude this section with a few more technical definitions which 
we will use only in the following Chapter on stochastic control.

\begin{definition}[Progressive Measurability]
    A continuous-time stochastic process $(X_t)$ is progressively measurable if
    for every time $t$, the map $[0,t]\times\Omega\rightarrow\mathbb{R}$ defined
    by $(s,\omega)\rightarrow X_s(\omega)$ is $\mathcal{B}(\mathbb{R})\times\mathcal{F}_t$-measurable.
    This is a slightly stronger condition than adaptedness, indeed, all progressively
    measurable processes are adapted but the converse is not true. 
\end{definition}

\begin{definition}[C\`{a}dl\`{a}g process]
    A stochastic process is called c\`{a}dl\`{a}g if it is right continuous with left 
    limits. Acronym from the french ``continue \`{a} droite, limite \`{a} gauche''.
\end{definition}

\begin{definition}[Semimartingale]
    A real-valued process $X$ is called a \emph{semimartingale} if it can be decomposed as
    \begin{equation}
        X_t = M_t + A_t
    \end{equation}
    where $M$ is a local martingale and $A$ is a c\`{a}dl\`{a}g, adapted process of locally
    bounded variation.
\end{definition}

Now that we have seen an overview of many key definitions of stochastic processes 
that will be of great utility when modelling financial markets, we turn to the 
theory of stochastic calculus. We specifically make use of It\^{o} calculus, 
which focuses on integration, as this will be most useful when we come to looking 
at Stochastic Differential Equations and controlled diffusion.

\section{Stochastic Integration}\label{sec:1.5}

Here we follow \cite{SCfFII} in our construction of the It\^{o} integral.

In order to make sense of the expression 
\begin{equation*}
    \int H\mathrm dW_t
\end{equation*}
where $H$ is an adapted stochastic process and $W$ is a standard Brownian Motion or 
Wiener Process, we turn to the trick used all the way back in section \ref{sec:1.3}
for the construction of the Lebesgue integral: Approximation by simple functions.

\begin{definition}[Stochastic Integral for Simple Processes]
    Suppose that $H$ is an adapted, simple process, in the sense that $\exists$ a 
    partition of $[0,T]$, $\Pi=\{[t_0,t_1),[t_1,t_2),\dots,[t_{n-1},t_n),[t_n,T]\}$ where 
    $H_t=c_i\;\forall\;t_i\leq t<t_{i+1}, i < n$ or $H_t=c_n$ for $t\in[t_n,T]$.
    Then we can define the stochastic integral as a sum:
    \begin{equation}
        I(t):=\sum_{j=0}^{n-1}H_{t_j}(W_{t_{j+1}}-W_{t_j})+H_{t_n}(W_T-W_{t_n})
    \end{equation}     
\end{definition}

Now we can approximate a more general $H$ by a simple stochastic process and 
take the limit of the above summation to arrive at It\^{o}'s notion of a stochastic 
integral.

\begin{definition}[It\^{o} (Stochastic) Integral]
    Let $W$ be a standard Wiener process as defined above, and let $H$ be adapted 
    (to $W$), and square-integrable:
    \begin{equation*}
        \int H_t^2\mathrm dt<\infty.
    \end{equation*}
    If $\{\Pi_n\}$ is a sequence of partitions on $[0,t]$ with mesh width decreasing
    to $0$, $t_0=0$, and $t_n=t$, then the \emph{It\^{o} integral} of $H$
    w.r.t. $W$ is the random variable
    \begin{equation}
        I(t)=\int_0^tH\mathrm dW:=\lim_{n\rightarrow\infty}\sum_{[t_{i-1},t_i]\in\pi_n}H_{t_{i-1}}(W_{t_i}-W_{t_{i-1}})
    \end{equation}
\end{definition}

It is possible to generalise this notion of stochastic integration to integration 
w.r.t. a continuous semimartingale, however this is not necessary for the content of 
this report. We continue by stating some of the properties of the It\^{o} integral
which we may need later on.

\begin{remark}[Properties of the It\^{o} Integral]
    \begin{itemize}
        \item Continuity: As a function of the upper limit of integration $t$, the 
        paths of $I(t)$ are continuous.
        \item Adaptivity: For each $t$, $I(t)$ is $\mathcal{F}_t$-measurable.
        \item Linearity: Summation of the integrals of processes is equivalent to
        integrating the summation. Ditto multiplication by a constant.
        \item Martingale: $I(t)$ is a martingale.
    \end{itemize}
\end{remark}

\begin{definition}[It\^{o} Processes]
    An It\^{o} process is any adapted stochastic process that can be written as the sum of a 
    deterministic integral w.r.t. time and a stochastic integral w.r.t. Brownian motion:
    \begin{equation}
        X_t=X_0+\int_0^t\mu_s\mathrm ds+\int_0^t\sigma_s\mathrm dW
    \end{equation}
    where $W$ is a standard Wiener process, $\sigma$ is predictable and integrable w.r.t. $W$,
    and $\mu$ is predictable and Lebesgue integrable. Equivalently, in differential form, we 
    may also write
    \begin{equation}
        \mathrm dX_t=\mu_t\mathrm dt + \sigma_t\mathrm dW_t
    \end{equation}
\end{definition}

\begin{remark}
    All It\^{o} processes are continuous semimartingales.
\end{remark}

\begin{lemma}[It\^{o}'s Lemma]
    This is probably most important result in stochastic calculus, and we will use 
    it several times in the rest of this report. It provides an analogue of the 
    chain rule, allowing us to find differentials for functions of It\^{o} processes. 
    Suppose $X$ is an It\^{o} process satisfying the differential form given above. 
    Let $f:[0,T]\times\mathbb{R}\rightarrow\mathbb{R}$ be continuously differentiable 
    at least once in the first argument and twice in the second. Then we have that
    \begin{equation}\label{eq:1.25}
        \mathrm df=\left(\frac{\partial f}{\partial t}+\mu_t\frac{\partial f}{\partial x}+\frac{\sigma_t^2}{2}\frac{\partial^2 f}{\partial x^2}\right)\mathrm dt + \sigma_t\frac{\partial f}{\partial x}\mathrm dW_t
    \end{equation}
    We can also state this result in the integral form, which is more mathematically 
    meaningful thanks to our definition of the stochastic integral given above:
    \begin{equation}\label{eq:1.26}
        f(t,X_t)-f(0,x_0)=\int_0^tf_t(s,W_s)+\mu_sf_x(s,X_s)+\frac{\sigma_s^2}{2}f_{xx}(s,W_s)\mathrm ds+\int_0^t\sigma_sf_x(s,W_s)\mathrm dW_s
    \end{equation}
\end{lemma}
\begin{proof}
    We present here a brief and informal proof. Suppose $X_t$ is an It\^{o} process
    as previously defined. If $f:[0,T]\times\mathbb{R}\rightarrow\mathbb{R}$ is a 
    twice differentiable scalar function, then it has the Taylor expansion
    \begin{equation}
        \mathrm df = \frac{\partial f}{\partial t}\mathrm dt+\frac{1}{2}\frac{\partial^2f}{\partial t^2}\mathrm dt^2+\dots+\frac{\partial f}{\partial x}\mathrm dx+\frac{1}{2}\frac{\partial^2f}{\partial x^2}\mathrm dx^2+\dots.
    \end{equation}
    Substituting $X_t$ for $x$ and therefore $\mu_t\mathrm dt + \sigma_t\mathrm dW_t$
    for $\mathrm dx$ gives
    \begin{align*}
        \mathrm df &= \frac{\partial f}{\partial t}\mathrm dt+\frac{1}{2}\frac{\partial^2f}{\partial t^2}\mathrm dt^2+\dots\\
        &+\frac{\partial f}{\partial x}(\mu_t\mathrm dt + \sigma_t\mathrm dW_t)+\frac{1}{2}\frac{\partial^2f}{\partial x^2}(\mu_t^2(\mathrm dt)^2 + 2\mu_t\sigma_t\mathrm dt\mathrm dW_t+ \sigma_t^2(\mathrm dW_t)^2)+\dots.
    \end{align*}
    As $\mathrm dt\rightarrow0$, the terms $\mathrm dt^2$ and $\mathrm dt\mathrm dW_t$ 
    tend to 0 faster than $\mathrm dW_t^2$ which is $\mathcal{o}(\mathrm dt)$ due to
    the quadratic variation of the Wiener process. Thus setting the $\mathrm dt^2$ 
    and $\mathrm dt\mathrm dW_t$ terms as well as terms with an order $>2$ to 0
    and setting $\mathrm dW_t^2=\mathrm dt$ we obtain the required expression.
\end{proof}

\section{Stochastic Differential Equations}\label{sec:1.6}

Next, we investigate the concept of a Stochastic Differential Equation. Again, as 
with this entire chapter, the content here is a short overview largely without proof.
A good introductory textbook for this content is \cite{ASDEs}. From a financial 
perspective, chapter 6 of \cite{SCfFII} provides a useful introduction, and in the 
context of stochastic control in finance, \cite{Pham} provides a recap in chapter 1.

\begin{definition}[Stochastic Differential Equation]
    A \emph{stochastic differential equation} (SDE) is an equation of the form
    \begin{equation}\label{eq:1.28}
        \mathrm dX_u=b(u,X_u)\mathrm du+\sigma(u,X_u)\mathrm dW_u.
    \end{equation}
    $b$ and $\sigma$ are given, Borel-measurable functions, called the
    \emph{drift} and \emph{diffusion} respectively. We also specify an initial condition
    of the form $X_t=x$, where $t\geq0$ and $x\in\mathbb{R}$ are specified. The problem
    then is to find a stochastic process $X_s$ defined for $s\geq t$, such that
    \begin{align*}
        X_t&=x\\
        X_s&=X_t+\int_t^sb(u,X_u)\mathrm du+\int_t^s\sigma(u,X_u)\mathrm dW_u.
    \end{align*}
\end{definition}

\begin{definition}[Strong Solution]
    A strong solution to this SDE starting at time $t$ is a progressively measurable 
    process $X$ such that for $t\leq s$:
    $$X_s=X_t+\int_{t}^{s}b(X_u,\alpha_u)\mathrm du+\int_t^s\sigma(X_u,\alpha_u)\mathrm dW_u$$
    and
    $$\int_t^s|b(X_u,\alpha_u)|\mathrm du+\int_t^s|\sigma(X_u,\alpha_u)|^2\mathrm du<\infty$$
    a.s.
\end{definition}

\begin{theorem}\label{thm:1.6.1}
    Suppose there exists a deterministic constant $K$ and an $\mathbb{R}$-valued process
    $k$ such that for every $t\in[0,T],\omega\in\Omega,x,y\in\mathbb{R}$:
    \begin{align}
        |b(t,x,\omega)-b(t,y,\omega)|+|\sigma(t,x,\omega)-\sigma(t,y,\omega)|&\leq K|x-y|,\\
        |b(t,x,\omega)+\sigma(t,x,\omega)|&\leq k_t(\omega)+K|x|,\textrm{ with}\\
        \mathbb{E}\left[\int_0^tk_u^2\mathrm du\right]&<\infty\;\forall\;t\in[0,T].
    \end{align}
    Then under these conditions, there exists for all $t\in[0,T]$ a strong solution 
    to the SDE \ref{eq:1.28} starting at time $t$ with initial condition $X_t=x$.
    
    Moreover, this solution is pathwise unique, meaning that if $X$ and $Y$ are two
    such strong solutions, we have $\mathbb{P}(X_s=Y_s\;\forall\;t\leq s)=1.$ Calling 
    the solution $X$, we also have that $X$ is square-integrable: For all $T>t$, there 
    exists a constant $C_T$ such that
    \begin{equation}
        \mathbb{E}\left[\sup_{t\leq s\leq T}|X_s|^p\right]\leq C_t(1+|x|^p).
    \end{equation}
    The proof of this is pages long and quite dry, so we skip it here. It can be found
    in Chapter 6 of \cite{Krylov}.
\end{theorem}

\begin{definition}[Infinitessimal Generator]
    A useful concept is that of the generator of a diffusion process governed by 
    an SDE. We define it as follows:
    \begin{equation}
        \mathcal{L}_t(\omega)f(t,x):=b(t,x,\omega)\frac{\partial f}{\partial x}(t,x)+\frac{1}{2}\sigma^2\frac{\partial^2f}{\partial x^2}(t,x)
    \end{equation}
    which we can recognise as making up part of the $\mathrm dt$ term in It\^{o}'s lemma.
\end{definition}

\begin{theorem}
    Given a strong solution $X$ to the SDE (\ref{eq:1.28}), and a function $f$ of 
    class $C^{1,2}$ on $[0,T]\times\mathbb{R}$ (continuously differentiable at least 
    once in the first argument and twice in the second), we can write It\^{o}'s lemma 
    (\ref{eq:1.26}) for $s\geq t$ as 
    \begin{equation}\label{eq:1.30}
        f(s,X_s)=f(t,X_t)+\int_t^sf_t(u,X_u)+\mathcal{L}_uf(u,X_u)\mathrm du + \int_t^s\sigma(u,X_u)f_x(u,X_u)\mathrm dW_u
    \end{equation}
\end{theorem}

\begin{definition}[Geometric Brownian Motion]
    A \emph{geometric brownian motion} is an adapted stochastic process which solves 
    the following stochastic differential equation
    \begin{equation}
        \mathrm dS_t=\mu S_t\mathrm dt + \sigma S_t\mathrm dW_t
    \end{equation}
    for $\mu,\sigma\in\mathbb{R}$ and where $W$ is a standard Wiener process. This
    is an example of an SDE with an explicit (strong) solution: In general, this 
    is not the case, but one-dimensional linear SDEs all have this property.
    By It\^{o}'s formula (\ref{eq:1.25}) with $f(t,S_t)=\log S_t$, we can write
    \begin{align*}
        \mathrm df&=\left(\mu S_t\frac{\partial f}{\partial x}+\frac{\sigma^2S_t^2}{2}\frac{\partial^2f}{\partial x^2}\right)\mathrm dt +\sigma S_t\frac{\partial f}{\partial x}\mathrm dS_t\\
        &=\left(\mu S_t\frac{1}{S_t}-\frac{\sigma^2S_t^2}{2}\frac{1}{S_t^2}\right)\mathrm dt+\frac{\sigma S_t}{S_t}\mathrm dW_t\\
        &=\left(\mu-\frac{\sigma^2}{2}\right)\mathrm dt+\sigma\mathrm dW_t,
    \end{align*}
    hence, in the integral form,
    \begin{align*}
        \log S_t&=\log S_0+\int_0^t\mu-\frac{\sigma^2}{2}\mathrm ds+\int_0^t\sigma\mathrm dW_s\\
        &=\log S_0+\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma(W_t-W_0)\\
        S_t&=S_0e^{\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma W_t}
    \end{align*}
    and we arrive at the canonical formula for the GBM, where $S_0$ is the initial 
    value of the process.
\end{definition}
