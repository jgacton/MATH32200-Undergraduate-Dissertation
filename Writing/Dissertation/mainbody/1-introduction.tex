\section{Introduction}
This section aims to equip the reader with both the motivation and mathematical 
tools to begin to formalise problems in stochastic optimal control and mathematical 
finance, by first providing some background material on financial markets, their 
participants, and their structure, and then setting up the basic elements of 
measure-theoretic probability theory and stochastic processes which we will use to 
describe them. We will end with a discussion of the market-making problem and how 
we might go about formalising it.

\section{Financial Markets}
A market is simply some social structure that attempts to match those who want to 
sell a good or service to those who want to buy it. Modern financial markets, 
thanks to recent innovations such as the internet, satellite communication, and 
fibre-optic cables, are perhaps the most interconnected and widespread markets in 
human history. 

Most people may have heard of the New York Stock Exchange, London Stock Exchange, 
or NASDAQ, but these are only one type of exchange for one type of financial asset, 
namely equity (part ownership of a corporate entity, individually called ``stocks'' 
or ``shares'').There are also markets for commodities (oil, gas, industrial metals, 
precious metals, live cattle and more), bonds (pieces of government or corporate 
debt, where the holder receives fixed interest payments), currencies (including 
cryptocurrencies), and derivatives which are legal contracts whose value is some 
function of the price of a specified underlying asset. In total, on an average day, 
tens of trillions of US dollars worth of assets change hands.

All markets, whatever the good or service being exchanged, have something in common: 
Every seller needs a buyer, and every buyer needs a seller. But this raises some 
natural questions: What happens if no-one wants to sell (or buy)? What happens if 
the only prices at which people are willing to sell is far out of reach of those 
who want to buy? Enter the \textit{dealer}: An entity who provides \textit{liquidity} 
(ease of exchange) to market participants. A dealer does this by simultaneously 
offering to both buy and sell the particular asset, offering to buy at a slightly 
lower price than they offer to sell. This known as ``making a market'', and dealers 
in modern parlance may also be called ``market-makers''.

\subsection*{Dealers}
Dealers provide a crucial service in financial markets: By providing these quotes, 
they narrow the \textit{spread} - the difference between the prices at which one can 
buy or sell an asset in the market. Hence, entities who may need to trade even in 
adverse market scenarios (such as companies needing to buy foreign currency to pay 
workers abroad, or oil producers seeking to hedge their production) know that they 
can reliably find a buyer or seller, regardless of the uncertainty of other market 
participants such as \textit{speculators} - those believe that a certain asset is 
under or overvalued, and trade it with the sole motive of making money buy selling 
it for more than they bought it or vice-versa.

Of course, there is no free lunch. Dealers do not provide this service to the market 
out of the goodness of their own hearts - they too have a profit motive. While the 
presence of dealers in the market narrows the spread, it does not eliminate it. 
The dealers aim is to be constantly selling the asset for a slightly higher price 
than it is buying it, and taking the spread as profit. In modern electronic markets 
with very high trading volumes, even in heavily traded assets with very narrow 
spreads, a spread of only 0.01\$ multiplied across millions or billions of trades 
can be very lucrative for the dealers who are fast enough.

\subsection*{The Limit Orderbook}
So far we have discussed markets as an abstract concept, but in order to build a 
mathematical model of the dealer, we need to specify the framework under which the 
market operates. Most modern electronic exchanges, including those mentioned above, 
operate some version of a \textit{limit orderbook} where participants can place two 
types of orders: a \textit{limit order} or a \textit{market order} depending on their 
needs. Limit orders specify a side (bid or ask, buying or selling), a quantity (how 
many units of the asset to buy/sell), and a price at which the order should be 
executed. These enter a queue of limit orders at the particular price level. Market 
orders specify a side and a quantity, but not a price: The exchange operates a 
\textit{matching engine} which takes incoming market orders and attempts to match 
them to the existing limit orders, and if two orders match, they are executed and a 
trade occurs. 

For an example, consider the orderbook illustrated by figure \ref{fig:orderbook}, and
suppose that individual limit orders may only be placed for 1-share lots. If a market 
order is placed to buy 10 lots, then the trade will occur at \$1.01, the dealer/s will 
sell and the placer of the market order will buy, and both the market order and the 10
lowest limit ask orders will be removed from the market. So immediately after this 
trade, there will be 20 shares left available to be sold at the \$1.01 price level. 
However, suppose that a market order is placed to buy 30 units. In this case, the 
orders will still be matched, the buyer will buy 30 units for \$1.01 apiece but all of 
the limit orders at \$1.01 will be taken off the exchange, and the market mid-point 
price has now moved up from \$1.00 to \$1.005. If a market order is placed to buy 100
shares, since there are only 80 shares available to be sold, only these 80 will be 
bought for an average price of $\frac{30\times1.01\$+50\times1.02\$}{80}=1.01625\$.$
On the other hand, if a market order is placed and there are no limit orders to match 
it against, the market order would not be executed at all and be voided.

Finally, suppose we place a limit 
order into this market to buy 10 shares for \$0.90. Thus, for our order to ever be 
executed, a market order or sequence of market orders would have to come in and move
the market mid-price by $\approx10\%$ in order for our order to be touched. Hence in a 
given (small) interval of time, it is intuitively very unlikely that our order will
be executed, especially when you consider that a move of $10\%$ is roughly how 
much you might expect a stock to move over a year, let alone over a fraction of a 
trading day. This is one of the fundamental ideas that we will employ to model our 
dealing agent: The probability that a limit order will execute is a decreasing 
function of its distance from the mid-price.

\begin{figure}
\centering
    \begin{tabular}{ |c|c|c| } 
        \hline
        Side & Price /\$ & Volume \\ 
        \hline
        A & 1.02 & 50 \\
        A & 1.01 & 30 \\
        N/A & 1.00 & 0 \\
        B & 0.99 & 25 \\ 
        B & 0.98 & 45 \\
        \hline
    \end{tabular}
    \caption{An example orderbook}
    \label{fig:orderbook}
\end{figure}

We have also seen the key difference between market and limit orders in action: Limit 
orders guarantee price, but do not guarantee that all or any of the order will be 
filled. Market orders guarantee that as much of the order as possible will be filled, 
but they do not guarantee the price at which the trade will occur.

We can also observe that the market provides us with a way to estimate the true value 
of the asset. Classical economic theory dictates that in aggregate, market participants 
react quickly and rationally to new information about a particular asset, meaning that 
market prices reflect the consensus opinion of market participants about the value of 
traded assets. The spread exists because people would only want to sell for slightly 
more than something is worth, and buy it for slightly less. Hence, if you really want 
to buy an asset you have to pay a premium to ``\textit{cross the spread}'' to acquire 
it. From this we can determine that the true price of the asset at a point in time 
lies somewhere in between the maximum bid price and the minimum ask price for the asset 
at that time. The most common estimator in the literature and in practice is simply 
the average of these two values - the mid-market price, but other estimators do exist 
such as the volume-weighted average price (VWAP) which takes into account the volume 
of the bids vs asks. For the rest of this report we will use the mid-price as our 
estimator for the ``true'' value of an asset.

The aim for the rest of this report is to build up a model of how a dealer should 
behave to maximise their returns in the presence of uncertainty: namely, uncertainty 
about the path that the true value of the stock might take. In order to do this, we 
will need to make use of some basic results from measure/probability theory and 
stochastic processes, which we will summarise below. We will also briefly introduce 
some tools from stochastic calculus. Familiarity with standard results from a 
first-year undergraduate level course in real analysis, probability, and statistics 
is assumed.

\section{Measure Theory and Probability}

\begin{definition}[$\sigma$-algebra]
    A family $\mathcal{F}\subseteq\mathcal{P}(\Omega)$ of sets is called a $\sigma$-algebra if 
    \begin{itemize}
        \item $\Omega\in\mathcal{A},$
        \item for every countable collection of sets $A_1,A_2,...\in\mathcal{F},\;\bigcup_{n}A_n\in\mathcal{F},$
        \item for every $A\in\mathcal{F}, A^{\mathrm c}\in\mathcal{F}.$
    \end{itemize}
\end{definition}

\begin{remark}
    The pair $(\Omega,\mathcal{F})$ is called a \emph{measurable space}. Any set $A\in\mathcal{F}$
    is called $\mathcal{F}$-\emph{measurable} or simply \emph{measurable}.
\end{remark}

\begin{definition}
    A \emph{measure} $\mu$ on a $\sigma$-algebra $\mathcal{F}$ is a set function
    $\mu:\mathcal{F}\rightarrow[0,\infty]$ such that $\forall$ mutually disjoint
    sets $A_1,A_2,...\in\mathcal{A}$ with $\bigcup_nA_n\in\mathcal{A},$
    \begin{equation}
        \mu\left(\bigcup_{n=1}^{\infty}A_n\right)=\sum_{n=1}^{\infty}\mu(A_n)
    \end{equation}
\end{definition}

\begin{remark}
    If $\mu(\Omega)=1$ then we call $\mu$ a \emph{probability measure}, and often
    use $\mathbb{P}$ instead. In this case the triplet $(\Omega,\mathcal{F},\mathbb{P})$
    is called a \emph{probability space}.
\end{remark}

\begin{lemma}
    Let $\mathcal{A}\subseteq\mathcal{P}(\Omega)$ Then $\exists$ a smallest $\sigma$-algebra 
    $\sigma(\mathcal{A})$ that contains all sets from $\mathcal{A}.$
\end{lemma}
\begin{proof}
    The intersection of $\sigma$-algebras is a $\sigma$-algebra, so to find the 
    smallest containing some collection of sets, take the intersection of all $\sigma$-
    algebras containing those sets.
\end{proof}

\begin{remark}
    The above $\sigma(\mathcal{A})$ is usually called the $\sigma$-algebra
    \emph{generated} by $\mathcal{A}$.
\end{remark}

\begin{definition}[The Borel $\sigma$-algebra]
    Consider the collection 
    \begin{equation*}
        \mathcal{A}=\{(a,b):a,b\in\mathbb{R}\cup\{-\infty,\infty\},a<b\}
    \end{equation*}
    Then define $\mathcal{B}(\mathbb{R}):=\sigma(\mathcal{A})$ the \emph{Borel 
    $\sigma$-algebra}. This is the smallest $\sigma$-algebra containing all open
    sets in $\mathbb{R}$. A set $B\in\mathcal{B}$ is a \emph{Borel set}.
\end{definition}

\begin{definition}[Measurable functions]
    Let $(\Omega,\mathcal{F})$ be a measurable space. A function $f:\Omega\rightarrow\mathbb{R}$
    is \emph{measurable} if for any $B\in\mathcal{B}$,
    \begin{equation*}
        f^{-1}(B)\in\mathcal{F}.
    \end{equation*}
\end{definition}

\begin{definition}[Simple functions]
    A \emph{simple function} is a finite linear combination of 
    characteristic (or indicator) functions of measurable sets:
    \begin{equation}
        \phi=\sum_{i=1}^nc_i\chi_{A_i}
    \end{equation}
    where $c_i\in\mathbb{R}$ and $A_i\in\mathbb{X}$.
    It is in standard representation if $X=\cup_{i=1}^nA_i$,
    the sets $A_i$ are pairwise disjoint, and the numbers $c_i$
    are distinct.
\end{definition}

\begin{definition}[Integral of a simple function]
    Consider a non-negative simple function written in standard form as given above.
    Then the \emph{integral} of $\phi$ \emph{with respect to $\mu$} is
    \begin{equation}
        \int\phi\mathrm d\mu:=\sum_{i=1}^nc_i\mu(A_i)
    \end{equation}
    which takes values in $\bar{\mathbb{R}}$.
\end{definition}

\begin{lemma}[Approximation by simple functions]
    Let $f\in M(X,\mathbb{X})$, $f\geq0.$ Then there exists a sequence
    $(\phi_n)$ in $M(X,\mathbb{X})$ such that
    \begin{itemize}
        \item $0\leq\phi_n(x)\leq\phi_{n+1}(x)\;\forall\;x\in X,n\in\mathbb{N}$,
        \item $\lim_{n\rightarrow\infty}\phi_n(x)=f(x)$,
        \item Each $\phi_n$ is a simple function.
    \end{itemize}
\end{lemma}

\begin{definition}[Integral of a non-negative measurable function]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$ 
    \emph{with respect to $\mu$} is 
    \begin{equation*}
        \int f\mathrm d\mu := \sup\left\{\int\phi\mathrm d\mu : 0\leq\phi\leq f, \phi\textrm{ is a simple measurable function}\right\}\in\bar{\mathbb{R}}.
    \end{equation*}
\end{definition}

\begin{definition}[Integral of a non-negative measurable function over a set]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$
    \emph{with respect to $\mu$ over set $A\in \mathbb{X}$} is
    \begin{equation}
        \int_A f\mathrm d\mu:=\int f\chi_A\mathrm d\mu
    \end{equation}
\end{definition}

\begin{definition}[Integrable functions]
    Let $(X,\mathbb{X},\mu)$ be a measure space. $f:X\rightarrow\mathbb{R}$
    is \emph{integrable} iff 
    \begin{equation}
        \int f^+\mathrm d\mu<+\infty \textrm{ and }\int f^-\mathrm d\mu<+\infty
    \end{equation}
    where $f^+:=\max\{f,0\}$ and $f^-:=-\min\{f,0\}$.
    We then define
    \begin{equation}
        \int f\mathrm d\mu:=\int f^+\mathrm d\mu -\int f^-\mathrm d\mu
    \end{equation}
    and for $A\in\mathbb{X}$
    \begin{equation}
        \int_A f\mathrm d\mu:=\int_A f^+\mathrm d\mu -\int_A f^-\mathrm d\mu
    \end{equation}
\end{definition}

\begin{remark}
    All of the standard properties of integrals that one would expect
    to hold such as linearity are also true for the Lebesgue integral 
    defined above. The Lebesgue integral also coincides with the Riemann
    and Regulated integrals for all Riemann-integrable and regulated functions respectively.
\end{remark}

\begin{definition}[Random variables]
    Recall from above that a probability space \\$(\Omega,\mathcal{F},\mathbb{P})$
    is simply a measure space $(X,\mathbb{X},\mu)$ where $\mu(X)=1.$ In this case,
    a measurable function $X:\Omega\rightarrow\mathbb{R}$ can be called
    a random variable. 
\end{definition}

\begin{definition}[Expectation]
    The notion of the \emph{expectation} of a \textbf{random variable} is exactly equivalent
    to the notion of the \emph{integral} of a \textbf{measurable function}.
    To be precise,
    \begin{equation}
        \mathbb{E}[X]:=\int X\mathrm d\mathbb{P}
    \end{equation}
\end{definition}

\begin{definition}[$\sigma-$algebra generated by a random variable]
    The $\sigma$-algebra generated by a random variable is
    $\sigma(Y):=\sigma(Y^{-1}(\mathcal{B}(\mathbb{R})))$
\end{definition}

\begin{definition}[Conditional Expectation]
    Suppose $\mathcal{H}\subseteq\mathcal{F}$ is a sub-$\sigma$-algebra
    of $\mathcal{F}.$ Then a \emph{conditional expectation} of random variable
    $X$ given $\mathcal{H}$ is any $\mathcal{H}$-measurable function $\Omega\rightarrow\mathbb{R}$
    which satisfies
    \begin{equation}
        \int_H \mathbb{E}[X|H]\mathrm d\mathbb{P}=\int_H X\mathrm d\mathbb{P}
    \end{equation}
    for any $H\in\mathcal{H}$. We define the conditional expectation with respect
    to a random variable as 
    \begin{equation}
        \mathbb{E}[X|Y]:=\mathbb{E}[X|\sigma(Y)]
    \end{equation}
    where $\sigma(Y)$ is the $\sigma$-algebra generated by $Y$.
\end{definition}

\begin{theorem}[Tonelli]
    Let $X_n\geq0$ be random variables. Then 
    \begin{equation}\label{eq:1.11}
        \mathbb{E}\left[\sum_{k=1}^\infty X_k\right]=\sum_{k=1}^\infty\mathbb{E}[X_k]
    \end{equation}
    and the statement also holds with an integral instead of a sum.
\end{theorem}

\begin{theorem}[Fubini]
    Let $X_n$ be random variables with $\mathbb{E}\left[\sum_{k=1}^\infty|X_k|\right]<\infty$.
    Then 
    \begin{equation}
        \mathbb{E}\left[\sum_{k=1}^\infty X_k\right]=\sum_{k=1}^\infty\mathbb{E}[X_k]
    \end{equation}
    and the statement also holds with an integral instead of a sum.
\end{theorem}

\begin{definition}[Moment Generating Functions]
    The \emph{Moment Generating Function} (MGF) of a random variable $X$ is defined as follows
    \begin{equation}
        M_X(t):=\mathbb{E}[e^{tX}]
    \end{equation}
\end{definition}

\begin{remark}
    The MGF of the normal distribution is a commonly used tool when dealing with
    Brownian Motion and functions of Brownian Motion as we will do throughout this
    report. Suppose $X\sim\mathcal{N}(\mu,\sigma^2)$. Then
    \begin{equation}
        M_X(t)=\mathbb{E}[e^{tX}]=e^{t\mu+\frac{t^2\sigma^2}{2}}
    \end{equation}
\end{remark}

\section{Stochastic Processes}

\begin{definition}[Filtrations \& Adaptedness]
    A \emph{filtered space} is $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n=0}^\infty,\mathbb{P})$
    where $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space and 
    $\mathcal{F}_0\subseteq\mathcal{F}_1\subseteq\dots\subseteq\mathcal{F}$
    are $\sigma$-algebras, jointly called a \emph{filtration.} We also define
    $\mathcal{F}_\infty:=\sigma(\cup_n\mathcal{F}_n)\subseteq\mathcal{F}.$ We
    say a stochastic process or sequence of random variables $X_n$ is adapted to
    the filtration $(\mathcal{F}_n)_{n\geq0}$ if for every $n$, $X_n$ is $\mathcal{F}_n$
    -measurable. 
\end{definition}

\begin{definition}[Martingales]
    A process $(M_n)_{n\geq0}$ in a filtered probability space is a
    \emph{martingale with respect to a filtration $(\mathcal{F}_n)_{n\geq0}$}
    if
    \begin{itemize}
        \item $M_n$ is adapted to $\mathcal{F}_n$,
        \item $\mathbb{E}[M_n]<\infty\;\forall\;n\geq0$,
        \item $\mathbb{E}[M_{n+1}|\mathcal{F}_n]=M_n\textrm{ a.s. }\forall\;n\geq0.$
    \end{itemize}
\end{definition}

\begin{definition}[Poisson Process]
    Let $\lambda:\mathbb{R}^d\rightarrow[0,\infty)$ be a measurable and
    integrable function such that for every bounded region $B$ the d-dimensional
    volume integral of $\lambda$ is finite:
    \begin{equation}
        \Lambda(B)=\int_B\lambda(x)\mathrm dx<\infty
    \end{equation}
    Then for every collection of disjoint bounded Borel-measurable sets
    $B_1,\dots,B_k$, an inhomogeneous \emph{Poisson Point Process} with
    \emph{intensity function} $\lambda$ has distribution
    \begin{equation}
        \mathbb{P}\{N(B_i)=n_i,i=1,\dots,k\}=\prod_{i=1}^k\frac{(\Lambda(B_i))^{n_i}}{n_i!}e^{-\Lambda(B_i)}.
    \end{equation}
    Moreover,
    \begin{equation}
        \mathbb{E}[N(B)]=\Lambda(B).
    \end{equation}
\end{definition}

\begin{definition}[Brownian Motion]
    Let $\mathcal{F}_t$ be a filtration. A stochastic process $W=(W_t)_{t\geq0}$
    is a standard one-dimensional \emph{Brownian Motion} or \emph{Wiener Process}
    if it satisfies the following:
    \begin{itemize}
        \item $W_0=0$ a.s.,
        \item Independent increments: $W_{t+s}-W_t$ is independent of $\mathcal{F}_t\;\forall\;t,s\geq0$,
        \item $W$ has stationary Gaussian increments: $W_{t+s}-W_t\sim\mathcal{N}(0,s)$,
        \item $W$ has continuous sample paths: $W_t(\omega)$ is a continuous function of $t\;\forall\;\omega\in\Omega$.
    \end{itemize}
\end{definition}

\begin{definition}[Predictable Processes]
    A stochastic process $X_t$ is \emph{predictable} (in the discrete sense) 
    if $X_{t+1}$ is $\mathcal{F}_{t}$ measurable for all $t$. If $X_t$
    is a continous stochastic process, then it is predictable if it is 
    measurable with respect to the $\sigma$-algebra generated by all left-continuous
    adapted processes.
\end{definition}

\begin{definition}[Progressive Measurability]
    A continuous-time stochastic process $(X_t)$ is progressively measurable if
    for every time $t$, the map $[0,t]\times\Omega\rightarrow\mathbb{R}$ defined
    by $(s,\omega)\rightarrow X_s(\omega)$ is $\mathcal{B}(\mathbb{R})\times\mathcal{F}_t$-measurable.
    This is a slightly stronger condition than adaptedness, indeed, all progressively
    measurable processes are adapted but the converse is not true. 
\end{definition}

\begin{definition}[C\`{a}dl\`{a}g processes]
    Right continuous with left limits. Acronym from the french
    ``continue \`{a} droite, limite \`{a} gauche''.
\end{definition}

\begin{definition}[Semimartingales]
    A real-valued process $X$ is called a \emph{semimartingale} if it can be decomposed as
    \begin{equation}
        X_t = M_t + A_t
    \end{equation}
    where $M$ is a local martingale and $A$ is a c\`{a}dl\`{a}g, adapted process of locally
    bounded variation.
\end{definition}

\section{Stochastic Integration}

\begin{definition}[It\^{o} (Stochastic) Integral]
    Let $W$ be a standard Wiener process as defined above, and let $H$ be a c\`{a}dl\`{a}g,
    adapted (to $W$), and locally bounded process. If $\{\pi_n\}$ is a sequence of partitions
    on $[0,t]$ with mesh width decreasing to $0$, then the \emph{It\^{o} integral} of $H$
    w.r.t. $W$ is the random variable
    \begin{equation}
        \int_0^tH\mathrm dW:=\lim_{n\rightarrow\infty}\sum_{[t_{i-1},t_i]\in\pi_n}H_{t_{i-1}}(W_{t_i}-W_{t_{i-1}})
    \end{equation}
\end{definition}

\begin{definition}[It\^{o} Processes]
    An It\^{o} process is any adapted stochastic process that can be written as the sum of a 
    deterministic integral w.r.t. time and a stochastic integral w.r.t. Brownian motion:
    \begin{equation}
        X_t=X_0+\int_0^t\mu_s\mathrm ds+\int_0^t\sigma_s\mathrm dW
    \end{equation}
    where $W$ is a standard Wiener process, $\sigma$ is predictable and integrable w.r.t. $W$,
    and $\mu$ is predictable and Lebesgue integrable. Equivalently, in differential form, we 
    may also write
    \begin{equation}
        \mathrm dX_t=\mu_t\mathrm dt + \sigma_t\mathrm dW_t
    \end{equation}
\end{definition}

\begin{lemma}[It\^{o}'s Lemma]
    Probably most important result in stochastic calculus. Provides an analogue of the chain rule,
    allowing us to find differentials for functions of It\^{o} processes. Suppose $X$ is an It\^{o}
    process satisfying the differential form given above. Let $f:[0,T]\times\mathbb{R}\rightarrow\mathbb{R}$
    be continuously differentiable at least once in the first argument and twice in the second.
    Then we have that
    \begin{equation}
        \mathrm df=\left(\frac{\partial f}{\partial t}+\mu_t\frac{\partial f}{\partial x}+\frac{\sigma_t^2}{2}\frac{\partial^2 f}{\partial x^2}\right)\mathrm dt + \sigma_t\frac{\partial f}{\partial x}\mathrm dW_t
    \end{equation}
\end{lemma}
\begin{proof}
    Taylor expansions
\end{proof}

\section{Stochastic Differential Equations}\label{sec:1.6}
\begin{itemize}
    \item From PDE to SDE
    \item Brownian motion as the solution to an SDE
    \item Geometric Brownian Motion
\end{itemize}

\begin{definition}[Strong Solution]
    A strong solution to this SDE starting at time $t$ is a progressively measurable process $X$ such that for $s\leq t$:
    $$X_s=X_t+\int_{t}^{s}b(X_u,\alpha_u)du+\int_t^s\sigma(X_u,\alpha_u)dW_u$$
    and
    $$\int_t^s|b(X_u,\alpha_u)|du+\int_t^s|\sigma(X_u,\alpha_u)|^2du<\infty$$
    a.s.
\end{definition}

\begin{definition}[Geometric Brownian Motion]
    A \emph{geometric brownian motion} is an adapted stochastic process which solves the following
    stochastic differential equation
    \begin{equation}
        dS_t=\mu S_t\mathrm dt + \sigma S_t\mathrm dW_t
    \end{equation}
    for $\mu,\sigma\in\mathbb{R}$ and where $W$ is a standard Wiender process.
    By It\^{o}'s formula with $f(S_t)=\log S_t$, we can write
    \begin{align*}
        \mathrm df(S_t)&=\frac{1}{S_t}\mathrm dS_t-\frac{1}{2S_t^2}(\mathrm dS_t)^2\\
        &=\mu\mathrm dt+\sigma\mathrm dW_t-\frac{1}{2}\sigma^2\mathrm dt\\
        \implies \log S_t&=\log S_0+\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma W_t\\
        \implies S_t&=S_0e^{\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma W_t}
    \end{align*}
    and we arrive at the canonical formula for the GBM, where $S_0$ is the initial value of the process.
\end{definition}
