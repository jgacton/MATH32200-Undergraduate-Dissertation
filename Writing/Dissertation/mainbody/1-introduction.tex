\section{Introduction}
This chapter aims to equip the reader with both the motivation and mathematical 
tools to begin to formalise the market-making problem. In section \ref{sec:1.2}
we will introduce the concepts of financial markets, order books and dealers, and 
qualitatively describe how a dealer may wish to behave to optimise their revenue. We
will then use section \ref{sec:1.3} to briefly recap some basic measure and probability 
theory before turning to stochastic processes in continuous time in section 
\ref{sec:1.4}. In sections \ref{sec:1.5} and \ref{sec:1.6} we introduce stochastic 
calculus, looking at stochastic integration, It\^{o}'s lemma, and finally stochastic 
differential equations and the existence and uniqueness of their solutions. A brief 
outline of the rest of this report is given at the end of section \ref{sec:1.2}
once we have described the problem we will be aiming to solve.

\section{Financial Markets}\label{sec:1.2}
A market is some structure that attempts to match those who want to 
sell a good or service to those who want to buy it. Modern financial markets 
thanks to innovations such as the internet, satellite communication, and 
fibre-optic cables are perhaps the most interconnected and widespread markets in 
human history. 

Most people may have heard of the New York Stock Exchange, London Stock Exchange, 
or NASDAQ, but these are only one type of exchange for one type of financial asset, 
namely \emph{equities}, individually called \emph{stocks} 
or \emph{shares}. There are also markets for \emph{commodities} such as oil, gas, and metals, \emph{bonds}, 
which are pieces of government or corporate 
debt where the holder receives fixed interest payments, currencies, including 
cryptocurrencies, and \emph{derivatives}, which are legal contracts whose value is some 
function of the price of a specified underlying asset. On an average day
trillions of US dollars worth of assets change hands (\cite{ADV}).

All markets, whatever the good or service being exchanged, have something in common: 
Every seller needs a buyer, and every buyer needs a seller. This raises some 
natural questions: What happens if no-one wants to sell (or buy)? What happens if 
the only prices at which people are willing to sell is far out of reach of those 
who want to buy? 

\subsection*{Dealers} 
The solution is the \textit{dealer}, which is an entity who provides \textit{liquidity}
(ease of exchange) to market participants (\cite{trading}). A dealer does this by 
simultaneously offering to both buy and sell the particular asset, offering to buy at a 
slightly lower price than they offer to sell. This is known as \emph{making a market}, and 
dealers in modern parlance may also be called \emph{market makers}.

By providing these bid and ask quotes, they narrow the \textit{spread}, the difference 
between the prices at which one can buy or sell an asset in the market. 
Of course, there is no free lunch. Dealers do not provide this service for free as they 
too have a profit motive. While the presence of dealers in the market narrows the spread, 
it does not eliminate it (\cite{trading}). 
The dealer's aim is to be continuously selling assets for a slightly higher price 
than it is buying them, and taking the spread as profit. In modern electronic markets 
with very high trading volumes, even in heavily traded assets with very narrow 
spreads, a spread of only 0.01\$ multiplied across millions or billions of trades 
can be very lucrative for the dealers who are fast enough.

\subsection*{The Limit Orderbook}
So far we have discussed markets conceptually, but in order to build a 
mathematical model of the dealer, we need to specify the framework under which the 
market operates. Most modern electronic exchanges 
operate some version of a \textit{limit orderbook} where participants can place two 
types of orders, \textit{limit orders} or \textit{market orders}. 
Limit orders specify a side (bid or ask, buying or selling), a quantity (how 
many units of the asset to buy/sell), and a price at which the order should be 
executed. These enter a queue of limit orders at the particular price level. Market 
orders specify a side and a quantity, but not a price. The exchange operates a 
\textit{matching engine} which takes incoming market orders and attempts to match 
them to the existing limit orders, and if two orders match, they are executed and a 
trade occurs (\cite{trading}). 

For an example, consider the orderbook illustrated by Figure \ref{fig:orderbook}, and
suppose that individual limit orders may only be placed for 1-share lots. If a market 
order is placed to buy 10 lots, then the trade will occur at \$1.01, the dealer/s will 
sell and the placer of the market order will buy, and both the market order and the 10
lowest limit ask orders will be removed from the market. Immediately after this 
trade there will be 20 shares left available to be sold at the \$1.01 price level. 
However, suppose that a market order is placed to buy 30 units. In this case, the 
orders will still be matched, the buyer will buy 30 units for \$1.01 apiece but all of 
the limit orders at \$1.01 will be taken off the exchange, and the market mid-point 
price will move up from \$1.00 to \$1.005. If a market order is placed to buy 100
shares, since there are only 80 shares available to be sold, only these 80 will be 
bought for an average price of $\frac{30\times1.01\$+50\times1.02\$}{80}=1.01625\$$
and the remaining 20 shares of the market order will be void.
Moreover, if a market order is placed and there are no limit orders to match 
it against, the market order would not be executed at all and be voided (\cite{trading}).

Finally, suppose we place a limit 
order into this market to buy 10 shares for \$0.90. Thus, for our order to ever be 
executed, a market order or sequence of market orders would have to come in and move
the market mid-price by $\approx10\%$. Hence in a 
given, small interval of time, it is very unlikely that our order will
be executed, especially when we consider that a move of $10\%$ is roughly how 
much we might expect a stock to move over a year (\cite{SP500}). This is one of the fundamental 
ideas that we will employ to model our 
dealing agent: The probability that a limit order will execute is a decreasing 
function of its distance from the mid-price (\cite{AS2008}).

\begin{figure}
\centering
    \begin{tabular}{ |c|c|c| } 
        \hline
        Side & Price /\$ & Volume \\ 
        \hline
        A & 1.02 & 50 \\
        A & 1.01 & 30 \\
        N/A & 1.00 & 0 \\
        B & 0.99 & 25 \\ 
        B & 0.98 & 45 \\
        \hline
    \end{tabular}
    \caption{An example orderbook}
    \label{fig:orderbook}
\end{figure}

We have also seen the key difference between market and limit orders in action: Limit 
orders guarantee price, but do not guarantee that all or any of the order will be 
filled. Market orders guarantee that as much of the order as possible will be filled, 
but they do not guarantee the price at which the trade will occur.

We can also observe that the orderbook provides us with a way to estimate the true value 
of the asset. We notice that there are in fact two prices for the asset depending on whether 
you are buying or selling. If you are buying, you pay the ask price, if you are selling,
the bid price. The spread is determined by the dealers in the market, and exists to compensate 
them for both their operational costs such as salaries and electricity, and their inventory 
costs since they service both sides of the market and thus hold inventories of risky
securities (\cite{trading}). Hence, if you want 
to buy an asset you have to pay a premium to \emph{cross the spread} to acquire 
it. Due to these facts, most models assume that the true value of the asset either 
coincides with or is tending towards some value in between the highest bid and lowest ask
over time, and the most commonly used estimator in the literature and in practice is 
the mid-market price or mid-price, $\frac{p^a+p^b}{2}$ (\cite{trading}). In chapter \ref{chap:3}
when discussing the model of \textcite{AS2008}, we will use the mid-price as our reference 
price around which to make a market.

The aim for subsequent chapters is to build up a model of how a dealer should 
behave to maximise their returns in the presence of uncertainty about the path that 
the true value of the stock might take. To do this, we 
will need to make use of some basic results from measure \& probability theory and 
stochastic processes, which we will summarise in sections \ref{sec:1.3} and \ref{sec:1.4}. 
We will also briefly introduce some tools from stochastic calculus in sections \ref{sec:1.5} 
and \ref{sec:1.6}. Familiarity with the standard results given in the Bristol 
first-year undergraduate mathematics courses in real analysis, probability, and statistics 
is assumed. We skip the vast majority of proofs in this chapter in the interest of 
brevity.

\section{Measure Theory and Probability}\label{sec:1.3}

We begin by formalising the notion of what events in a probability space are.
In elementary treatments of probability theory, the set of events is given no particular 
structure, but this is not sufficient for a rigorous treatment of uncountable sample 
spaces. 

All of the results in this section come from the third year Bristol Measure Theory and Integration
and Martingale Theory with Applications courses, with the exception of the Fubini-Tonelli
theorem which is a slight generalisation of the one given in the Martingales course.

\begin{definition}[$\sigma$-algebra]
    A family $\mathcal{F}\subseteq\mathcal{P}(\Omega)$ of sets is called a $\sigma$-algebra if 
    \begin{itemize}
        \item $\Omega\in\mathcal{F},$
        \item for every countable collection of sets $A_1,A_2,...\in\mathcal{F},\;\bigcup_{n}A_n\in\mathcal{F},$
        \item for every $A\in\mathcal{F}, A^{\mathrm c}\in\mathcal{F}.$
    \end{itemize}
\end{definition}

\begin{remark}
    The pair $(\Omega,\mathcal{F})$ is called a \emph{measurable space}. Any set $A\in\mathcal{F}$
    is called $\mathcal{F}$-\emph{measurable} or simply \emph{measurable}.
\end{remark}

A measure is a function that provides a notion of magnitude to a measurable set. 
In $\mathbb{R}^n$, the canonical measure is the Lebesgue measure, which generalises the 
notions of length, area, and volume to sets in $\mathbb{R}$, $\mathbb{R}^2$, and $\mathbb{R}^n:n\geq3$
respectively.
In the context of probability theory, the magnitude or measure of a set or event is 
simply the likelihood that it will occur.

\begin{definition}[Measure]
    A \emph{measure} $\mu$ on a $\sigma$-algebra $\mathcal{F}$ is a set function
    $\mu:\mathcal{F}\rightarrow[0,\infty]$ such that $\forall$ mutually disjoint
    sets $A_1,A_2,...\in\mathcal{A}$ with $\bigcup_nA_n\in\mathcal{A},$
    \begin{equation*}
        \mu\left(\bigcup_{n=1}^{\infty}A_n\right)=\sum_{n=1}^{\infty}\mu(A_n).
    \end{equation*}
\end{definition}

\begin{remark}
    The triplet $(\Omega,\mathcal{F},\mu)$ is called a measure space. If $\mu(\Omega)
    =1$ then we call $\mu$ a \emph{probability measure}, and often use $\mathbb{P}$ 
    instead. In this case the triplet $(\Omega,\mathcal{F},\mathbb{P})$ is called a 
    \emph{probability space}.
\end{remark}

Next we see that we can generate $\sigma$-algebras from sets of sets and use 
this to construct the Borel $\sigma$-algebra on $\mathbb{R}$. This is the canonical
$\sigma$-algebra for use over $\mathbb{R}$, containing all open intervals and hence all 
open sets as well as all closed intervals, semi-open intervals and singletons.
\begin{lemma}
    Let $\mathcal{A}\subseteq\mathcal{P}(\Omega)$ Then $\exists$ a smallest $\sigma$-algebra 
    $\sigma(\mathcal{A})$ that contains all sets from $\mathcal{A}.$
\end{lemma}
\begin{proof}
    The intersection of $\sigma$-algebras is a $\sigma$-algebra. Thus to find the 
    smallest $\sigma$-algebra containing some collection of sets, we take the intersection
    of all $\sigma$-algebras containing those sets.
\end{proof}

\begin{remark}
    The above $\sigma(\mathcal{A})$ is usually called the $\sigma$-algebra
    \emph{generated} by $\mathcal{A}$.
\end{remark}

\begin{definition}[The Borel $\sigma$-algebra]
    Consider the collection 
    \begin{equation*}
        \mathcal{A}=\{(a,b):a,b\in\mathbb{R}\cup\{-\infty,\infty\},a<b\},
    \end{equation*}
    the set of all open intervals in $\mathbb{R}$. Then define 
    $\mathcal{B}(\mathbb{R}):=\sigma(\mathcal{A})$ the \emph{Borel 
    $\sigma$-algebra}. This is the smallest $\sigma$-algebra containing all open
    sets in $\mathbb{R}$. A set $B\in\mathcal{B}$ is a \emph{Borel set}.
\end{definition}

Next we turn to functions whose domain is a measurable space. We also look at simple 
functions, define the integral of a simple function, approximate non-negative measurable
functions by simple functions and arrive at the notion of the Lebesgue integral, a slightly
stronger integral than the Riemann or Regulated integral studied in a first-year analysis 
course.

\begin{definition}[Measurable functions]
    Let $(\Omega,\mathcal{F})$ be a measurable space. A function $f:\Omega\rightarrow\mathbb{R}$
    is \emph{measurable} if for any $B\in\mathcal{B}$,
    \begin{equation*}
        f^{-1}(B)\in\mathcal{F}.
    \end{equation*}
\end{definition}

\begin{definition}[Simple functions]
    A \emph{simple function} is a finite linear combination of 
    characteristic (or indicator) functions of measurable sets:
    \begin{equation*}
        \phi=\sum_{i=1}^nc_i\chi_{A_i}
    \end{equation*}
    where $c_i\in\mathbb{R}$ and $A_i\in\mathbb{X}$.
    It is in standard representation if $X=\cup_{i=1}^nA_i$,
    the sets $A_i$ are pairwise disjoint, and the numbers $c_i$
    are distinct.
\end{definition}

\begin{definition}[Integral of a simple function]
    Consider a non-negative simple function written in standard form as given above.
    Then the \emph{integral} of $\phi$ \emph{with respect to $\mu$} is
    \begin{equation*}
        \int\phi\mathrm d\mu:=\sum_{i=1}^nc_i\mu(A_i)
    \end{equation*}
    which takes values in $\mathbb{R}\cup\{-\infty,\infty\}$.
\end{definition}

\begin{lemma}[Approximation by simple functions]
    Let $f\in M(X,\mathbb{X})$, $f\geq0.$ Then there exists a sequence
    $(\phi_n)$ in $M(X,\mathbb{X})$ such that
    \begin{itemize}
        \item $0\leq\phi_n(x)\leq\phi_{n+1}(x)\;\forall\;x\in X,n\in\mathbb{N}$,
        \item $\lim_{n\rightarrow\infty}\phi_n(x)=f(x)$,
        \item Each $\phi_n$ is a simple function.
    \end{itemize}
\end{lemma}

\begin{definition}[Integral of a non-negative measurable function]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$ 
    \emph{with respect to $\mu$} is 
    \begin{equation*}
        \int f\mathrm d\mu := \sup\left\{\int\phi\mathrm d\mu : 0\leq\phi\leq f, \phi\textrm{ is a simple measurable function}\right\}\in\bar{\mathbb{R}}.
    \end{equation*}
\end{definition}

\begin{definition}[Integral of a non-negative measurable function over a set]
    Let $f\in M^+(X,\mathbb{X})$. Then the \emph{integral} of $f$
    \emph{with respect to $\mu$ over set $A\in \mathbb{X}$} is
    \begin{equation*}
        \int_A f\mathrm d\mu:=\int f\chi_A\mathrm d\mu.
    \end{equation*}
\end{definition}

\begin{definition}[Integrable functions]
    Let $(X,\mathbb{X},\mu)$ be a measure space. $f:X\rightarrow\mathbb{R}$
    is \emph{integrable} $\iff$
    \begin{equation*}
        \int f^+\mathrm d\mu<+\infty \textrm{ and }\int f^-\mathrm d\mu<+\infty
    \end{equation*}
    where $f^+:=\max\{f,0\}$ and $f^-:=-\min\{f,0\}$.
    We then define
    \begin{equation*}
        \int f\mathrm d\mu:=\int f^+\mathrm d\mu -\int f^-\mathrm d\mu
    \end{equation*}
    and for $A\in\mathbb{X}$
    \begin{equation*}
        \int_A f\mathrm d\mu:=\int_A f^+\mathrm d\mu -\int_A f^-\mathrm d\mu.
    \end{equation*}
\end{definition}

\begin{remark}
    The standard property of linearity of integrals also holds for the Lebesgue 
    integral, following from the linearity of the summation used in the integration of 
    simple functions. The Lebesgue integral also coincides with the Riemann
    and Regulated integrals for all Riemann-integrable and regulated functions respectively.
\end{remark}

Now that we have seen a brief introduction to measure theory and integration, we turn to 
probability theory.

\begin{definition}[Random variables]
    Recall from above that a probability space \\$(\Omega,\mathcal{F},\mathbb{P})$
    is simply a measure space $(X,\mathbb{X},\mu)$ where $\mu(X)=1.$ In this case,
    a measurable function $X:\Omega\rightarrow\mathbb{R}$ can be called
    a random variable. 
\end{definition}

\begin{definition}[Expectation]
    The notion of the \emph{expectation} of a \textbf{random variable} is exactly equivalent
    to the notion of the \emph{integral} of a \textbf{measurable function}.
    We have
    \begin{equation*}
        \mathbb{E}[X]:=\int X\mathrm d\mathbb{P}
    \end{equation*}
    for $X:\Omega\rightarrow\mathbb{R}$ in a probability space $(\Omega,\mathcal{F},\mathbb{P})$.
\end{definition}

\begin{definition}[$\sigma-$algebra generated by a random variable]
    The $\sigma$-algebra generated by a random variable $Y:\Omega\rightarrow\mathbb{R}$
    is $\sigma(Y):=\sigma(Y^{-1}(\mathcal{B}(\mathbb{R})))$.
\end{definition}

\begin{definition}[Conditional Expectation]
    Suppose $\mathcal{H}\subseteq\mathcal{F}$ is a sub-$\sigma$-algebra
    of $\mathcal{F}.$ Then a \emph{conditional expectation} of random variable
    $X$ given $\mathcal{H}$, is any $\mathcal{H}$-measurable function 
    $V:\Omega\rightarrow\mathbb{R}$ with $\mathbb{E}[V]<\infty$ which satisfies
    \begin{equation*}
        \int_H V\mathrm d\mathbb{P}=\int_H X\mathrm d\mathbb{P}
    \end{equation*}
    for any $H\in\mathcal{H}$. We then define the notational convenience
    \begin{equation*}
        \mathbb{E}[X|\mathcal{H}]:=V.
    \end{equation*}
    The conditional expectation with respect to a random variable is defined according
    to
    \begin{equation*}
        \mathbb{E}[X|Y]:=\mathbb{E}[X|\sigma(Y)]
    \end{equation*}
    where $\sigma(Y)$ is the $\sigma$-algebra generated by $Y$.
\end{definition}

\begin{theorem}[Tower rule / Law of iterated conditional expectation]
    Let $X$ be a random variable on probability space $(\Omega,\mathcal{F},\mathbb{P})$
    with $\mathbb{E}[|X|]<\infty$. Let $\mathcal{G}\subset\mathcal{H}$ be sub $\sigma$-
    algebras, $\mathcal{G}$ the courser and $\mathcal{H}$ the finer. Then:
    \begin{equation*}
        \mathbb{E}[\mathbb{E}[X|\mathcal{G}]|\mathcal{H}]=\mathbb{E}[\mathbb{E}[X|\mathcal{H}]|\mathcal{G}]=\mathbb{E}[X|\mathcal{G}].
    \end{equation*}
\end{theorem}

We now turn to a useful theorem from measure theory concerning 
the swapping of integrals (or integral and expectation, since expectation is 
equivalent to integration in the probability space). This a slight generalisation 
of the version of the theorem encountered in the Bristol Martingale Theory course,
we use the version given by \textcite{tao}.

\begin{theorem}[Fubini-Tonelli]
    Let $(\Omega,\mathcal{F},\mathbb{P})$ and $(\mathbb{R},\mathcal{B},\lambda)$
    be two $\sigma$-finite measure spaces (this is a technical condition beyond the 
    scope of this introduction, all measure spaces encountered from here on out will
    be $\sigma$-finite). Let $f:\Omega\times\mathbb{R}\rightarrow\mathbb{R}$ be a 
    measurable function w.r.t. both measure spaces. Then
    \begin{equation}\label{eq:1.13}
        \int\int f(x,y)\mathrm d\mathbb{P}\mathrm d\lambda=\int\mathbb{E}[f(x,y)]\mathrm d\lambda=\mathbb{E}\left[\int f(x,y)\mathrm d\lambda\right]=\int \int f(x,y)\mathrm d\lambda\mathrm d\mathbb{P}.
    \end{equation}
\end{theorem}

\begin{definition}[Moment Generating Functions]
    The \emph{Moment Generating Function} (MGF) of a random variable $X$ is defined as follows
    \begin{equation*}
        M_X(t):=\mathbb{E}[e^{tX}].
    \end{equation*}
\end{definition}

\begin{remark}
    The MGF of the normal distribution is a commonly used tool when dealing with
    Brownian Motion and functions of Brownian Motion as we will do throughout this
    report. Suppose $X\sim\mathcal{N}(\mu,\sigma^2)$. Then
    \begin{equation}
        M_X(t)=\mathbb{E}[e^{tX}]=e^{t\mu+\frac{t^2\sigma^2}{2}}.
    \end{equation}
\end{remark}

\section{Stochastic Processes}\label{sec:1.4}

Next we move on to look at Stochasic Processes, which are sequences
of random variables, typically viewed as moving through time. Going forward we will 
need a few properties regarding measurability and some common examples of widely used 
stochastic processes for modelling real-world phenomena. Firstly, we need to introduce 
some extra structure to our probability space, representing the information about the 
process that we receive over time.

This section recaps some content from the Bristol Probability 2 and Martingale Theory
courses, and also brings in some new material which is cited when introduced.

\begin{definition}[Filtrations \& Adaptedness]
    A \emph{filtered space} is $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n=0}^\infty,\mathbb{P})$
    where $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space and 
    $\mathcal{F}_0\subseteq\mathcal{F}_1\subseteq\dots\subseteq\mathcal{F}$
    are $\sigma$-algebras, jointly called a \emph{filtration.} We also define
    $\mathcal{F}_\infty:=\sigma(\cup_n\mathcal{F}_n)\subseteq\mathcal{F}.$ 
    
    We say a stochastic process or sequence of random variables $X_n$ is adapted to
    the filtration $(\mathcal{F}_n)_{n\geq0}$ if for every $n$, $X_n$ is 
    $\mathcal{F}_n$-measurable. 
\end{definition}

\begin{definition}[Martingales]
    A process $(M_n)_{n\geq0}$ in a filtered probability space is a
    \emph{martingale with respect to a filtration $(\mathcal{F}_n)_{n\geq0}$}
    if
    \begin{itemize}
        \item $M_n$ is adapted to $\mathcal{F}_n$,
        \item $\mathbb{E}[M_n]<\infty\;\forall\;n\geq0$,
        \item $\mathbb{E}[M_{n+1}|\mathcal{F}_n]=M_n\textrm{ a.s. }\forall\;n\geq0.$
    \end{itemize}
\end{definition}

\begin{definition}[(Inhomogeneous) Poisson Process]
    Let $\lambda:\mathbb{R}\rightarrow[0,\infty)$ be a measurable and
    integrable function such that for every bounded set $B$ the integral of 
    $\lambda$ is finite:
    \begin{equation}
        \Lambda(B)=\int_B\lambda(x)\mathrm dx<\infty.
    \end{equation}
    In particular, the function $\Lambda$ is a measure.
    Then for every collection of disjoint bounded Borel-measurable sets
    $B_1,\dots,B_k$, an inhomogeneous \emph{Poisson Point Process} with
    \emph{intensity function} $\lambda$ has distribution
    \begin{equation}
        \mathbb{P}\{N(B_i)=n_i,i=1,\dots,k\}=\prod_{i=1}^k\frac{(\Lambda(B_i))^{n_i}}{n_i!}e^{-\Lambda(B_i)}.
    \end{equation}
    Moreover,
    \begin{equation}
        \mathbb{E}[N(B)]=\Lambda(B).
    \end{equation}
    This definition comes from \textcite{PointTheory}.
\end{definition}

\begin{definition}[Brownian Motion]
    Let $\mathcal{F}_t$ be a filtration. A stochastic process $W=(W_t)_{t\geq0}$
    is a standard one-dimensional \emph{Brownian Motion} or \emph{Wiener Process}
    if it satisfies the following (\cite{BMSC}):
    \begin{itemize}
        \item $W_0=0$ a.s.,
        \item Independent increments: $W_{t+s}-W_t$ is independent of $\mathcal{F}_t\;\forall\;t,s\geq0$,
        \item $W$ has stationary Gaussian increments: $W_{t+s}-W_t\sim\mathcal{N}(0,s)$,
        \item $W$ has continuous sample paths: $W_t(\omega)$ is a continuous function of $t\;\forall\;\omega\in\Omega$.
    \end{itemize}
\end{definition}

\begin{definition}[Predictable Processes]
    A stochastic process $X_t$ is \emph{predictable} (in the discrete sense) 
    if $X_{t+1}$ is $\mathcal{F}_{t}$ measurable for all $t$. 
    
    If $X_t$ is a continous stochastic process, then it is predictable if it is 
    measurable with respect to the $\sigma$-algebra generated by all left-continuous
    adapted processes. 
    
    This includes all left-continuous stochastic processes
    since we can find $X_t$ by finding $\lim_{s\rightarrow t^-}X_s$ without needing 
    to observe $X$ at time $t$.
\end{definition}

\begin{definition}[Stopping Times]
    A random variable $\tau:\Omega\rightarrow[0,\infty]$ is a stopping time (with
    respect to the filtration $\mathcal{F}$) if $\forall\;t\in[0,T]$
    \begin{equation*}
        \{\tau\leq t\}:=\{\omega\in\Omega:\tau(\omega)\leq t\}\in\mathcal{F}_t.
    \end{equation*}
\end{definition}

This concept will be very useful later on when we look at the dynamic programming 
principle. In particular, any random time equal to a positive constant $t$ is a 
stopping time. We conclude this section with a few more technical definitions which 
we will use only in the subsequent chapter 2 on stochastic control.

\begin{definition}[Progressive Measurability]
    We use the definition given by \textcite{Pham} for this and for the next 
    three definitions in this section.
    A continuous-time stochastic process $(X_t)$ is progressively measurable if
    for every time $t$, the map $[0,t]\times\Omega\rightarrow\mathbb{R}$ defined
    by $(s,\omega)\rightarrow X_s(\omega)$ is $\mathcal{B}(\mathbb{R})\times\mathcal{F}_t$-measurable.
    This is a slightly stronger condition than adaptedness since all progressively
    measurable processes are adapted but the converse is not true. 
\end{definition}

\begin{definition}[C\`{a}dl\`{a}g process]
    A stochastic process is called c\`{a}dl\`{a}g if it is right continuous with left 
    limits. This acronym from the french ``continue \`{a} droite, limite \`{a} gauche''.
\end{definition}

\begin{definition}[Local Martingale]
    Let $X$ be a c\`{a}dl\`{a}g and adapted process. We say that $X$ is a local martingale
    if there exists a sequence of stopping times $(\tau_n)_{n\geq1}$ such that 
    $\lim_{n\rightarrow\infty}\tau_n=\infty$ a.s. and the process $X_{\min\{t,\tau_n\}}$
    is a martingale for all $n$.
\end{definition}

\begin{definition}[Semimartingale]
    A continuous real-valued process $X$ is called a \emph{semimartingale} if it can 
    be decomposed as
    \begin{equation}
        X_t = X_0 + M_t + A_t
    \end{equation}
    where $M$ is a continuous local martingale and $A$ is an adapted c\`{a}dl\`{a}g 
    process of locally bounded variation: $\forall\;\omega,t$
    \begin{equation*}
        \sup\sum_{i=1}^n|A_{t_i}(\omega)-A_{t_i-1}(\omega)|<\infty
    \end{equation*}
    where the supremum is taken over all subdivisions $0=t_0<t_1<\dots<t_n=t$ of 
    $[0,t]$.
\end{definition}

Now that we have seen an overview of key definitions of stochastic processes 
that will be helpful when modelling financial markets, we turn to the 
theory of stochastic calculus. We specifically make use of It\^{o} calculus, 
which focuses on integration, as this will be most useful when we come to looking 
at Stochastic Differential Equations and controlled diffusion.

\section{Stochastic Integration}\label{sec:1.5}

Throughout this section we follow \textcite{SCfFII} in our construction of the It\^{o} 
integral. In order to make sense of the expression 
\begin{equation*}
    \int H\mathrm dW_t
\end{equation*}
where $H$ is an adapted stochastic process and $W$ is a standard Wiener Process, 
we turn to the idea we saw in section \ref{sec:1.3}
for the construction of the Lebesgue integral: Approximation by simple functions.

\begin{definition}[Stochastic Integral for Simple Processes]
    Suppose that $H$ is an\\ adapted, simple process, in the sense that $\exists$ a 
    partition of $[0,T]$, \\$\Pi_n=\{[t_0,t_1),[t_1,t_2),\dots,[t_{n-1},t_n),[t_n,T]\}$ where 
    $H_t=c_i\;\forall\;t_i\leq t<t_{i+1}, i < n$ and $H_t=c_n$ for $t\in[t_n,T]$.
    Then we can define the stochastic integral as a sum:
    \begin{equation}
        I(t):=\sum_{j=0}^{n-1}H_{t_j}(W_{t_{j+1}}-W_{t_j})+H_{t_n}(W_T-W_{t_n}).
    \end{equation}     
\end{definition}

Now we can approximate a more general $H$ by a simple stochastic process and 
take the limit of the above summation to arrive at It\^{o}'s notion of a stochastic 
integral.

\begin{definition}[It\^{o} (Stochastic) Integral]
    Let $W$ be a standard Wiener process as defined above, and let $H$ be adapted 
    (to $W$), and square-integrable:
    \begin{equation*}
        \int H_t^2\mathrm dt<\infty.
    \end{equation*}
    If $\{\Pi_n\}$ is a sequence of partitions on $[0,t]$ with mesh width decreasing
    to $0$, $t_0=0$, and $t_n=t$, then the \emph{It\^{o} integral} of $H$
    with respect to $W$ is the random variable
    \begin{equation}
        I(t)=\int_0^tH\mathrm dW:=\lim_{n\rightarrow\infty}\sum_{[t_{i-1},t_i]\in\pi_n}H_{t_{i-1}}(W_{t_i}-W_{t_{i-1}}).
    \end{equation}
\end{definition}

We continue by stating some of the properties of the It\^{o} integral
which we will need later on.

\begin{remark}[Properties of the It\^{o} Integral]
    Below we list some elementary properties of the stochastic integral we have
    constructed:
    \begin{itemize}
        \item Continuity: As a function of the upper limit of integration $t$, the 
        paths of $I(t)$ are continuous.
        \item Adaptivity: For each $t$, $I(t)$ is $\mathcal{F}_t$-measurable.
        \item Linearity: Summation of the integrals of processes is equivalent to
        integrating the summation. Ditto multiplication by a constant.
        \item Martingale: $I(t)$ is a martingale.
    \end{itemize}
\end{remark}

\begin{definition}[It\^{o} Processes]
    An It\^{o} process is any adapted stochastic process that can be written as the sum of a 
    deterministic integral with respect to time and a stochastic integral with respect to Brownian motion:
    \begin{equation}
        X_t=X_0+\int_0^t\mu_s\mathrm ds+\int_0^t\sigma_s\mathrm dW
    \end{equation}
    where $W$ is a standard Wiener process, $\sigma$ is predictable and integrable with respect to $W$,
    and $\mu$ is predictable and Lebesgue integrable. Equivalently, in differential form, we 
    may also write
    \begin{equation}
        \mathrm dX_t=\mu_t\mathrm dt + \sigma_t\mathrm dW_t.
    \end{equation}
\end{definition}

\begin{remark}
    All It\^{o} processes are continuous semimartingales.
\end{remark}

\begin{lemma}[It\^{o}'s Lemma]
    This is probably most important result in stochastic calculus, and we will use 
    it several times in the rest of this report. It provides an analogue of the 
    chain rule, allowing us to find differentials for functions of It\^{o} processes. 
    Suppose $X$ is an It\^{o} process satisfying the differential form given above. 
    Let $f:[0,T]\times\mathbb{R}\rightarrow\mathbb{R}$ be continuously differentiable 
    at least once in the first argument and twice in the second. Then we have that
    \begin{equation}\label{eq:1.25}
        \mathrm df=\left(\frac{\partial f}{\partial t}+\mu_t\frac{\partial f}{\partial x}+\frac{\sigma_t^2}{2}\frac{\partial^2 f}{\partial x^2}\right)\mathrm dt + \sigma_t\frac{\partial f}{\partial x}\mathrm dW_t.
    \end{equation}
    We can also state this result in the integral form, which is more mathematically 
    meaningful thanks to our definition of the stochastic integral given above:
    \begin{equation}\label{eq:1.26}
        f(t,X_t)-f(0,x_0)=\int_0^tf_t(s,W_s)+\mu_sf_x(s,X_s)+\frac{\sigma_s^2}{2}f_{xx}(s,W_s)\mathrm ds+\int_0^t\sigma_sf_x(s,W_s)\mathrm dW_s.
    \end{equation}
\end{lemma}
\begin{proof}
    We present here a brief and informal proof. Suppose $X_t$ is an It\^{o} process
    as previously defined. If $f:[0,T]\times\mathbb{R}\rightarrow\mathbb{R}$ is a 
    twice differentiable scalar function then it has the Taylor expansion
    \begin{equation*}
        \mathrm df = \frac{\partial f}{\partial t}\mathrm dt+\frac{1}{2}\frac{\partial^2f}{\partial t^2}\mathrm dt^2+\dots+\frac{\partial f}{\partial x}\mathrm dx+\frac{1}{2}\frac{\partial^2f}{\partial x^2}\mathrm dx^2+\dots
    \end{equation*}
    Substituting $X_t$ for $x$ and, therefore, $\mu_t\mathrm dt + \sigma_t\mathrm dW_t$
    for $\mathrm dx$ gives
    \begin{align*}
        \mathrm df &= \frac{\partial f}{\partial t}\mathrm dt+\frac{1}{2}\frac{\partial^2f}{\partial t^2}\mathrm dt^2+\dots\\
        &+\frac{\partial f}{\partial x}(\mu_t\mathrm dt + \sigma_t\mathrm dW_t)+\frac{1}{2}\frac{\partial^2f}{\partial x^2}(\mu_t^2(\mathrm dt)^2 + 2\mu_t\sigma_t\mathrm dt\mathrm dW_t+ \sigma_t^2(\mathrm dW_t)^2)+\dots
    \end{align*}
    As $\mathrm dt\rightarrow0$, the terms $\mathrm dt^2$ and $\mathrm dt\mathrm dW_t$ 
    tend to 0 faster than $\mathrm dW_t^2$ which is $\textrm{o}(\mathrm dt)$ due to
    the quadratic variation of the Wiener process. Thus setting the $\mathrm dt^2$ 
    and $\mathrm dt\mathrm dW_t$ terms as well as terms with an order $>2$ to 0
    and setting $\mathrm dW_t^2=\mathrm dt$ we obtain the required expression.
\end{proof}

\section{Stochastic Differential Equations}\label{sec:1.6}

Next, we investigate the concept of a Stochastic Differential Equation, following chapter 
1 of \textcite{Pham}.

\begin{definition}[Stochastic Differential Equation]
    A \emph{stochastic differential equation} (SDE) is an equation of the form
    \begin{equation}\label{eq:1.28}
        \mathrm dX_u=b(u,X_u)\mathrm du+\sigma(u,X_u)\mathrm dW_u.
    \end{equation}
    $b$ and $\sigma$ are given and Borel-measurable functions, called the
    \emph{drift} and \emph{diffusion} respectively. We also specify an initial condition
    of the form $X_t=x$ where $t\geq0$ and $x\in\mathbb{R}$ are specified. The problem
    then is to find a stochastic process $X_s$ defined for $s\geq t$ such that
    \begin{align*}
        X_t&=x,\\
        X_s&=X_t+\int_t^sb(u,X_u)\mathrm du+\int_t^s\sigma(u,X_u)\mathrm dW_u.
    \end{align*}
\end{definition}

\begin{definition}[Strong Solution]
    A strong solution to this SDE starting at time $t$ is a progressively measurable 
    process $X$ such that for $t\leq s$:
    $$X_s=X_t+\int_{t}^{s}b(X_u,\alpha_u)\mathrm du+\int_t^s\sigma(X_u,\alpha_u)\mathrm dW_u$$
    and
    $$\int_t^s|b(X_u,\alpha_u)|\mathrm du+\int_t^s|\sigma(X_u,\alpha_u)|^2\mathrm du<\infty$$
    almost surely.
\end{definition}

\begin{remark}[Almost sure statements]
    Let $(X,\mathbb{X},\mu)$ be a measure space. A proposition $P$ holds $\mu$-almost-everywhere,
    if $\exists$ a set $N\in\mathbb{X}$ such that $\mu(N)=0$ and $P$ holds on $X\setminus N$.
    In a probability space with a given $\mathbb{P}$, we say the result holds almost surely (a.s.).
\end{remark}

\begin{theorem}\label{thm:1.6.1}
    Suppose there exists a deterministic constant $K$ and an $\mathbb{R}$-valued process
    $k$ such that for every $t\in[0,T],\omega\in\Omega,x,y\in\mathbb{R}$:
    \begin{align*}
        |b(t,x,\omega)-b(t,y,\omega)|+|\sigma(t,x,\omega)-\sigma(t,y,\omega)|&\leq K|x-y|,\\
        |b(t,x,\omega)+\sigma(t,x,\omega)|&\leq k_t(\omega)+K|x|,\textrm{ with}\\
        \mathbb{E}\left[\int_0^tk_u^2\mathrm du\right]&<\infty\;\forall\;t\in[0,T].
    \end{align*}
    Then under these conditions there exists for all $t\in[0,T]$ a strong solution 
    to the SDE \eqref{eq:1.28} starting at time $t$ with initial condition $X_t=x$.
    
    Moreover, this solution is pathwise unique, meaning that if $X$ and $Y$ are two
    such strong solutions, we have $\mathbb{P}(X_s=Y_s\;\forall\;t\leq s)=1.$ Calling 
    the solution $X$, we also have that $X$ is square-integrable: For all $T>t$, there 
    exists a constant $C_T$ such that
    \begin{equation*}
        \mathbb{E}\left[\sup_{t\leq s\leq T}|X_s|^p\right]\leq C_t(1+|x|^p).
    \end{equation*}
    We will skip this proof, but it can be found in chapter 6 of \textcite{Krylov}.
\end{theorem}

\begin{definition}[Infinitessimal Generator]
    A concept that we will make use of when discussing the Hamilton-Jacobi-Bellman equation
    in chapter \ref{chap:2} is that of the generator of a diffusion process governed by 
    an SDE. We define it as follows:
    \begin{equation}\label{eq:1.14}
        \mathcal{L}_t(\omega)f(t,x):=b(t,x,\omega)\frac{\partial f}{\partial x}(t,x)+\frac{1}{2}\sigma^2\frac{\partial^2f}{\partial x^2}(t,x)
    \end{equation}
    which we can recognise as making up part of the $\mathrm dt$ term in It\^{o}'s lemma.
\end{definition}

\begin{theorem}
    Given a strong solution $X$ to the SDE \eqref{eq:1.28}, and a function $f$ of 
    class $C^{1,2}$ on $[0,T]\times\mathbb{R}$ (continuously differentiable at least 
    once in the first argument and twice in the second), we can write It\^{o}'s lemma 
    \eqref{eq:1.26} for $s\geq t$ as 
    \begin{equation}\label{eq:1.30}
        f(s,X_s)=f(t,X_t)+\int_t^sf_t(u,X_u)+\mathcal{L}_uf(u,X_u)\mathrm du + \int_t^s\sigma(u,X_u)f_x(u,X_u)\mathrm dW_u.
    \end{equation}
\end{theorem}

\begin{definition}[Geometric Brownian Motion]
    A \emph{geometric brownian motion} is an adapted stochastic process which solves 
    the following stochastic differential equation
    \begin{equation}
        \mathrm dS_t=\mu S_t\mathrm dt + \sigma S_t\mathrm dW_t
    \end{equation}
    for $\mu,\sigma\in\mathbb{R}$ and where $W$ is a standard Wiener process. This
    is an example of an SDE with an strong solution. In general this 
    is not the case, but one-dimensional linear SDEs all have this property.
    By It\^{o}'s formula \eqref{eq:1.25} with $f(t,S_t)=\log S_t$ we can write
    \begin{align*}
        \mathrm df&=\left(\mu S_t\frac{\partial f}{\partial x}+\frac{\sigma^2S_t^2}{2}\frac{\partial^2f}{\partial x^2}\right)\mathrm dt +\sigma S_t\frac{\partial f}{\partial x}\mathrm dS_t\\
        &=\left(\mu S_t\frac{1}{S_t}-\frac{\sigma^2S_t^2}{2}\frac{1}{S_t^2}\right)\mathrm dt+\frac{\sigma S_t}{S_t}\mathrm dW_t\\
        &=\left(\mu-\frac{\sigma^2}{2}\right)\mathrm dt+\sigma\mathrm dW_t,
    \end{align*}
    hence, in the integral form,
    \begin{align*}
        \log S_t&=\log S_0+\int_0^t\mu-\frac{\sigma^2}{2}\mathrm ds+\int_0^t\sigma\mathrm dW_s\\
        &=\log S_0+\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma(W_t-W_0)\\
        S_t&=S_0e^{\left(\mu-\frac{\sigma^2}{2}\right)t+\sigma W_t}.
    \end{align*}
    and we arrive at the canonical formula for the GBM where $S_0$ is the initial 
    value of the process.
\end{definition}

Now imagine again the position of a dealer in a financial market. Considering a dealer
who is not trading, and assuming that asset prices evolve
according to an It\^{o} process $S$, their wealth will evolve according to the simple 
SDE $\mathrm dX_t=q\mathrm dS_t$ where $q$ is their inventory. However, when the dealer
is trading they can 
continuously update their bid and ask quotes, influencing the flow of orders 
they receive. The dealer \emph{controls} their wealth over time through the process $\alpha=\begin{pmatrix}p^a\\p^b\end{pmatrix}$
where $p^a$ and $p^b$ are the ask and bid quotes respectively, and this process 
$\alpha$ should not be determined in advance, but be a function of arguments such 
as time and the dealers current inventory so that the dealer can react to changing 
market conditions. Thus $\alpha$ itself is random as it depends on the 
flow of market orders received by the dealer.
Hence, the dealers wealth evolves according to the \emph{controlled diffusion}
\begin{equation*}
    \mathrm dX_t=\beta(t,\alpha_t)\mathrm dS_t.
\end{equation*}
In chapter \ref{chap:2} we will construct a general theory of how to deal with 
such processes with the goal of determining the \emph{optimal control} $\alpha^*$ with 
respect to some particular criteria, such as maximising a particular expected utility.
